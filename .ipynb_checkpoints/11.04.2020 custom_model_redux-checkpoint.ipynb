{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "# from tensorflow.keras.keras_preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import sys\n",
    "# import sklearn.model_selection as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_model = ka.ResNet50(\n",
    "#                         include_top=True,\n",
    "                        weights='imagenet',#,\n",
    "#                         classes=2,\n",
    "                        input_shape = (224, 224, 3)\n",
    "                        )\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# # base_model_add_layers = keras.Model(inputs = base_model.input, outputs = base_model.output)\n",
    "# # out_1 = keras.layers.GlobalAvgPool2D()(base_model.output)\n",
    "# # out_1 = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "# x = keras.layers.Flatten()(base_model.layers[-2].output)\n",
    "out_2 = keras.layers.Dense(512, activation='relu')(base_model.layers[-2].output)\n",
    "out_1 = keras.layers.Dense(1000, activation='softmax')(out_2)\n",
    "\n",
    "model = keras.Model(inputs = base_model.input, outputs = out_1)#, base_model.output, base_model.layers[-2].output])\n",
    "model_extra = keras.Model(inputs = model.input, outputs = [model.layers[-1].output, model.layers[-2].output, model.layers[-3].output])\n",
    "# opt = keras.optimizers.SGD(lr = 0.0001)\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "# base_model.compile(optimizer = opt, loss = '_crossentropy', metrics = 'accuracy')\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "model_extra.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# model.summary()\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = './ImageNet/organized_validation/'\n",
    "\n",
    "# data_batches = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"categorical\",\n",
    "# #     class_names=None,\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=1,\n",
    "#     image_size=(224, 224),\n",
    "#     shuffle=True,\n",
    "#     seed=13,\n",
    "# #     validation_split=None,\n",
    "# #     subset=None,\n",
    "#     interpolation=\"bilinear\"\n",
    "# #     follow_links=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38000 images belonging to 1000 classes.\n",
      "Found 12000 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "directory = './ImageNet/organized_validation/'\n",
    "\n",
    "resnet_preprocess = keras.applications.resnet.preprocess_input\n",
    "\n",
    "val_id_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = resnet_preprocess,\n",
    "                                                          validation_split = 0.25)\n",
    "# val_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "# val_id_gen = tensorflow.keras.preprocessing.image.ImageDataGenerator()\n",
    "# val_gen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_gen = val_id_gen.flow_from_directory(\n",
    "    directory, \n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb', \n",
    "    classes=None,\n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    seed=13,\n",
    "#     validation_split = 0.25,\n",
    "    subset = 'training',\n",
    "#     save_to_dir=None, \n",
    "#     save_prefix='', \n",
    "#     save_format='png', f\n",
    "#     ollow_links=False,\n",
    "#     subset=None, \n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "val_gen = val_id_gen.flow_from_directory(\n",
    "    directory, \n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb', \n",
    "    classes=None,\n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    seed=13,\n",
    "#     validation_split = 0.25,\n",
    "    subset = 'validation',\n",
    "#     save_to_dir=None, \n",
    "#     save_prefix='', \n",
    "#     save_format='png', f\n",
    "#     ollow_links=False,\n",
    "#     subset=None, \n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "# next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1188/1188 [==============================] - 4112s 3s/step - loss: 4.2216 - accuracy: 0.2753 - val_loss: 2.3641 - val_accuracy: 0.4874\n",
      "Epoch 2/10\n",
      "1188/1188 [==============================] - 3603s 3s/step - loss: 1.7577 - accuracy: 0.5976 - val_loss: 1.9088 - val_accuracy: 0.5486\n",
      "Epoch 3/10\n",
      "1188/1188 [==============================] - 3479s 3s/step - loss: 1.3099 - accuracy: 0.6841 - val_loss: 1.7587 - val_accuracy: 0.5757\n",
      "Epoch 4/10\n",
      "1188/1188 [==============================] - 3614s 3s/step - loss: 1.0542 - accuracy: 0.7413 - val_loss: 1.6992 - val_accuracy: 0.5922\n",
      "Epoch 5/10\n",
      "1188/1188 [==============================] - 3266s 3s/step - loss: 0.8650 - accuracy: 0.7871 - val_loss: 1.6618 - val_accuracy: 0.6030\n",
      "Epoch 6/10\n",
      "1188/1188 [==============================] - 2977s 3s/step - loss: 0.7162 - accuracy: 0.8227 - val_loss: 1.6452 - val_accuracy: 0.6064\n",
      "Epoch 7/10\n",
      "1188/1188 [==============================] - 2963s 2s/step - loss: 0.5893 - accuracy: 0.8580 - val_loss: 1.6652 - val_accuracy: 0.6010\n",
      "Epoch 8/10\n",
      "1188/1188 [==============================] - 3263s 3s/step - loss: 0.4800 - accuracy: 0.8894 - val_loss: 1.6621 - val_accuracy: 0.6092\n",
      "Epoch 9/10\n",
      "1188/1188 [==============================] - 2939s 2s/step - loss: 0.3898 - accuracy: 0.9156 - val_loss: 1.6860 - val_accuracy: 0.6087\n",
      "Epoch 10/10\n",
      "1188/1188 [==============================] - 2957s 2s/step - loss: 0.3142 - accuracy: 0.9369 - val_loss: 1.6840 - val_accuracy: 0.6147\n"
     ]
    }
   ],
   "source": [
    "# Train model on generator:\n",
    "\n",
    "history = model.fit(train_gen, validation_data = val_gen, epochs = 40, shuffle = True, workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine generator for encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.zeros((10000, 224, 224, 3))\n",
    "y_val = np.zeros((10000, 1000))\n",
    "\n",
    "# x_encoded = np.zeros((50000, 2048))\n",
    "# y_encoded = np.zeros((50000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(1, 6):\n",
    "    for i in range(10000):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        x, y = val_gen.next()\n",
    "        x_val[i, :, :, :] = x\n",
    "        y_val[i, :] = y\n",
    "\n",
    "    # x_train, x_val, y_train, y_val = train_test_split(x_val, y_val, train_size = .75, shuffle = True)\n",
    "\n",
    "#     out = model_extra.predict(x_val)\n",
    "    out = base_model.predict(x_val)\n",
    "    \n",
    "#     print(a.shape)\n",
    "#     print(b.shape)\n",
    "#     print(c.shape)\n",
    "\n",
    "    print(out.shape)\n",
    "\n",
    "    \n",
    "    pickle.dump( out, open( \"imagenet_val_1000_encoding_\" + str(z) + \".p\", \"wb\" ) )\n",
    "\n",
    "\n",
    "#     x_encoded[z:z+10000, :] = c\n",
    "#     y_encoded[z:z+10000, :] = y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.shape)\n",
    "\n",
    "for pred in out:\n",
    "#     print(pred.shape)\n",
    "    pred = pred.reshape(1, 1000)\n",
    "    decoded = keras.applications.resnet.decode_predictions(\n",
    "        pred, top=5\n",
    "    )\n",
    "    print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_intermediate[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = out_intermediate\n",
    "\n",
    "dist_from_first = []\n",
    "image_dict = {}\n",
    "index = 1444\n",
    "first_features = out[2][index]\n",
    "first_image = x_val[index][:,:,:]\n",
    "print(first_image.shape)\n",
    "\n",
    "# hash images:\n",
    "for idx in range(x_val.shape[0]):\n",
    "    image_dict[str(out[2][idx])] = x_val[idx] \n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(first_image/255)\n",
    "plt.show()\n",
    "\n",
    "# for i in range(400):\n",
    "#     if i % 25 == 0:\n",
    "#         print(i)\n",
    "for idx, item in enumerate(out[2]):\n",
    "    dist_from_first.append((np.linalg.norm(first_features-item), (str(item))))\n",
    "\n",
    "dist_from_first.sort()\n",
    "# print(dist_from_first)\n",
    "\n",
    "for i in range(20):\n",
    "    plt.clf()\n",
    "    img = image_dict[dist_from_first[i][1]]\n",
    "    plt.imshow(img/255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "    x, y = val_gen.next()\n",
    "#     x_val[i, :, :, :] = x\n",
    "#     y_val[i, :] = y\n",
    "    \n",
    "    out = base_model.predict(x)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(x/255)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
