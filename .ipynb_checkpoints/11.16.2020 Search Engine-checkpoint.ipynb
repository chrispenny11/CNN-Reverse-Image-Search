{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"]= 300\n",
    "mpl.rc('axes.spines',top=False,bottom=False,left=False,right=False);\n",
    "mpl.rc('axes',facecolor=(0,0,0,0),edgecolor=(0,0,0,0));\n",
    "mpl.rc(('xtick','ytick'),color=(0,0,0,0));\n",
    "import time\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "from annoy import AnnoyIndex\n",
    "import subprocess\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "from keras.applications.resnet import decode_predictions\n",
    "\n",
    "class searchEngine():\n",
    "\n",
    "    def __init__(self, encoding_user_set = 'resnet_1000'):\n",
    "\n",
    "        self.class_key = pd.read_csv('/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/imagenet_resnet_key.csv')\n",
    "        self.encoding_type = encoding_user_set\n",
    "        self.set_src()\n",
    "        try:\n",
    "            self.load_database()\n",
    "        except:\n",
    "            print('Must generate encodings for this setting.')\n",
    "\n",
    "    def brute_force_search_index(self, query_index, num_results, show_flag, normalized=False):\n",
    "\n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Use Numpy to calculate distance values:\n",
    "        dist_to_query = []\n",
    "        if normalized == True:\n",
    "            dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                            np.array(searcher._values)/np.linalg.norm(np.array(searcher._values), axis = 1).reshape(-1, 1)), axis = 1)\n",
    "        else:\n",
    "            dist_to_query = np.linalg.norm((query_vec - np.array(self._values)), axis = 1)\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = np.argsort(dist_to_query)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "            \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "    def show_results(self, query_idx, dist_rank, num_results):\n",
    "        \n",
    "        query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "\n",
    "        print(self._keys[query_idx])\n",
    "\n",
    "        concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "        for i in range(1, num_results + 1):\n",
    "            result_idx = dist_rank[i]\n",
    "            result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "            result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "            if len(np.array(result_img).shape) == 2:\n",
    "                result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "            elif np.array(result_img).shape == (224, 224, 4):\n",
    "                result_img = np.array(result_img)\n",
    "                result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "            concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "            print(self._keys[result_idx])\n",
    "\n",
    "        plt.clf()\n",
    "        plt.imshow(concat_img/255)\n",
    "        plt.show()\n",
    "        \n",
    "    def annoy_search_index(self, query_index, num_results, show_flag):\n",
    "        \n",
    "        # Query vector:\n",
    "        query_vec = np.array(self._values[query_index])\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, num_results+1)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "\n",
    "    def distributed_search(self, query_index, num_results, cluster_id):\n",
    "        \n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "        query_vec_str = ''\n",
    "        for elem in query_vec:\n",
    "            query_vec_str += str(elem) + ' '\n",
    "        query_vec_str = query_vec_str[:-1]\n",
    "#         print(query_vec_str)\n",
    "        \n",
    "        f = open(\"vec.txt\",\"w\")\n",
    "        f.write(query_vec_str)\n",
    "        \n",
    "#         subprocess.run(\"python3 distributed_prototype.py \" + str(self._s3_path) + \n",
    "#                        \" -r emr --cluster-id=\" + \n",
    "#                        str(cluster_id) + \n",
    "#                        \" --no-output --no-read-logs --region=us-east-2 --query=\" + \n",
    "#                        str(query_vec) + \" \" +\n",
    "#                        \" > output.txt\", shell = True)\n",
    "\n",
    "        subprocess.run(\"python3 distributed_prototype.py \" + \n",
    "                       str(self._s3_path) + \n",
    "                       \" -r emr --cluster-id=\" + \n",
    "                       str(cluster_id) + \n",
    "                       \" --no-read-logs --region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                       shell = True)\n",
    "    \n",
    "    \n",
    "#         with open('output.txt') as f:\n",
    "#             for line in f:\n",
    "#                 out = list(str(line).replace('[','').\n",
    "#                                      replace(']','').\n",
    "#                                      replace(',', '').\n",
    "#                                      replace('\"','').\n",
    "#                                      replace('1\\t','').\n",
    "#                                      replace('\\n', '').split(\" \"))\n",
    "\n",
    "#         print(out[1::2])\n",
    "        \n",
    "#         if show_flag == 1:\n",
    "#             query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "\n",
    "#             plt.clf()\n",
    "#             plt.imshow(query_img)\n",
    "#             plt.show()\n",
    "\n",
    "    def build_annoy_forest(self, tree_count, seed = 13):\n",
    "        \n",
    "        self._tree_count = tree_count\n",
    "        t = AnnoyIndex(len(self._values[0]), 'angular')\n",
    "        t.set_seed(seed)\n",
    "\n",
    "        for idx, item in enumerate(self._values):\n",
    "            t.add_item(idx, np.array(item))\n",
    "            \n",
    "        t.build(tree_count)\n",
    "        self._annoy_forest = t\n",
    "\n",
    "    def load_database(self):\n",
    "\n",
    "        with open(self._src) as f:\n",
    "            db =  json.load(f)\n",
    "\n",
    "        self._values = np.array([x for x in db.values()])\n",
    "        self._keys = list(db.keys())\n",
    "        \n",
    "        if self.encoding_type == 'combined':\n",
    "            \n",
    "            resnet_enc_norm = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(resnet_enc_norm.shape)\n",
    "            \n",
    "            self.encoding_type = 'ae_bottleneck_2048'\n",
    "            self.set_src()\n",
    "            self.encoding_type = 'combined'\n",
    "            \n",
    "            with open(self._src) as f:\n",
    "                db =  json.load(f)\n",
    "            \n",
    "            ae_enc_norm = np.array([x for x in db.values()])/np.linalg.norm(np.array([x for x in db.values()]),\n",
    "                                                                            axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(ae_enc_norm.shape)\n",
    "            \n",
    "            self._values = np.concatenate([resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "            \n",
    "            print(self._values.shape)\n",
    "        \n",
    "    def load_encoder(self, take_max='Yes'):\n",
    "        '''\n",
    "        Loads the original model and uses its paramemters to compile the encoding layers.\n",
    "        \n",
    "        Only available for relevant encoding types.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000':\n",
    "            self._encoderModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            underlying_model = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "                                             outputs = underlyingModel.layers[-2].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_simple_2048' and take_max == 'Yes':\n",
    "            underlyingModel = keras.models.load_model(\n",
    "                                    '/Users/ChrisPenny/Downloads/AE_Simple_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "                                             outputs = keras.layers.GlobalMaxPool2D()\n",
    "                                             (underlyingModel.layers[-12].output))\n",
    "            \n",
    "        elif self.encoding_type == 'ae_simple_2048' and take_max == 'No':\n",
    "            underlyingModel = keras.models.load_model(\n",
    "                                    '/Users/ChrisPenny/Downloads/AE_Simple_F4_0001_Final.h5')\n",
    "            \n",
    "            self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "                                             outputs = underlyingModel.layers[-12].output)\n",
    "\n",
    "#         elif self.encoding_type == 'ae_dense_2048' and take_max == 'Yes':\n",
    "#             underlyingModel = keras.models.load_model(\n",
    "#                                     '/Users/ChrisPenny/Downloads/AE_Dense_F4_0001_Final.h5')\n",
    "\n",
    "#             self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "#                                              outputs = keras.layers.GlobalMaxPool2D()\n",
    "#                                              (underlyingModel.layers[-12].output))\n",
    "            \n",
    "#         elif self.encoding_type == 'ae_dense_2048' and take_max == 'No':\n",
    "#             underlyingModel = keras.models.load_model(\n",
    "#                                     '/Users/ChrisPenny/Downloads/AE_Dense_F4_0001_Final.h5')\n",
    "            \n",
    "#             self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "#                                              outputs = underlyingModel.layers[-12].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_bottleneck_2048':\n",
    "            underlyingModel = keras.models.load_model(\n",
    "                                    '/Users/ChrisPenny/Downloads/AE_Bottleneck_F4_0001_Final.h5')\n",
    "            \n",
    "            self._encoderModel = keras.Model(inputs = underlyingModel.input, \n",
    "                                             outputs = underlyingModel.layers[-15].output)\n",
    "        else:\n",
    "            print('No model matching that encoding type.')\n",
    "            return\n",
    "\n",
    "        self._encoderModel.compile()\n",
    "\n",
    "    def prep_image(self, path):\n",
    "    \n",
    "        im = PIL.Image.open(path)\n",
    "        im_resize = im.resize((224, 224))\n",
    "        if np.array(im_resize).shape == (224, 224):\n",
    "            im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "        elif np.array(im_resize).shape == (224, 224, 4):\n",
    "            im_resize = np.array(im_resize)\n",
    "            im_resize = im_resize[:, :, 0:3]\n",
    "        \n",
    "        return np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    def encoder_search(self, query_url, num_results, show = 1):\n",
    "        \n",
    "        np_image = self.prep_image(query_url)\n",
    "        \n",
    "        query_encoding = self._encoderModel.predict(np_image)\n",
    "        \n",
    "        self.build_annoy_forest(10)\n",
    "        \n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_encoding[0], num_results+1)\n",
    "\n",
    "#         self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "        if show == 1:\n",
    "\n",
    "            im = PIL.Image.open(query_url)\n",
    "\n",
    "            plt.clf()\n",
    "            plt.imshow(im)\n",
    "            plt.show()\n",
    "\n",
    "            for i in range(1, num_results + 1):\n",
    "                result_idx = dist_ranking[i]\n",
    "                result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "\n",
    "                plt.clf()\n",
    "                plt.rcParams['figure.figsize'] = [12, 8]\n",
    "                plt.imshow(result_img)\n",
    "                plt.show()\n",
    "\n",
    "                print(self._keys[result_idx])\n",
    "\n",
    "    def load_decoder(self):\n",
    "        '''\n",
    "        Loads the original model and uses its paramemters to compile the decoding layers.\n",
    "        \n",
    "        Only available for relevant encoding types.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'ae_bottleneck_2048':\n",
    "            testModel = keras.models.load_model('/Users/ChrisPenny/Downloads/AE_Bottleneck_F4_0001_Final.h5')\n",
    "            self._decoderModel = keras.Model(inputs = underlyingModel.layers[-14].input, \n",
    "                                             outputs = underlyingModel.layers[-1].output)\n",
    "            \n",
    "    def reconstruct_image(self):\n",
    "        pass\n",
    "            \n",
    "    def save_scores(self, search_mode = 'annoy', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000):\n",
    "        '''\n",
    "        Scores encodings by ImageNet class as mean average precision.\n",
    "\n",
    "        Only valid for validation directories - otherwise leaky.\n",
    "        '''\n",
    "        \n",
    "        # Precompute normalization of each encoding:\n",
    "        # Saves a lot of runtime.\n",
    "        if normalized == True:\n",
    "            self._values_normed = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "\n",
    "        # Dictionary keeps track of scores by class:\n",
    "        score_dict = {}\n",
    "\n",
    "        for idx in range(num_classes*50):\n",
    "            \n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "                if normalized == True:\n",
    "                    dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                                    self._values_normed, \n",
    "                                                    axis = 1)\n",
    "                else:\n",
    "                    dist_to_query = np.linalg.norm(query_vec - self._values, \n",
    "                                                   axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, np.max(ranks) + 1)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Compare classes:\n",
    "            correct = 0\n",
    "            rank_idx = 0\n",
    "            # Note: First result is the image itself, so we skip it.\n",
    "            for jdx in range(1, np.max(ranks) + 1):\n",
    "\n",
    "                result_key = self._keys[dist_ranking[jdx]]\n",
    "                result_class = result_key[:result_key.find('/')]\n",
    "\n",
    "                if result_class == query_class:\n",
    "                    correct += 1\n",
    "\n",
    "                if ranks[rank_idx] == jdx:\n",
    "\n",
    "                    if query_class not in score_dict:\n",
    "                        score_dict[query_class] = {}\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "                    elif ranks[rank_idx] not in score_dict[query_class]:\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "\n",
    "                    score_dict[query_class][ranks[rank_idx]].append(correct/ranks[rank_idx])#, end_time - start_time))\n",
    "\n",
    "                    rank_idx += 1\n",
    "                \n",
    "                score_dict['time'] = end_time - start_time\n",
    "                \n",
    "        if search_mode == 'annoy':\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)             \n",
    "        else:\n",
    "            if normalized == True:\n",
    "                with open(search_mode + \"_normalized_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)        \n",
    "            else:\n",
    "                with open(search_mode + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)        \n",
    "\n",
    "    def generate_encodings(self):\n",
    "        '''\n",
    "        generate_encodings\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        cwd = os.getcwd()\n",
    "        cwd += '/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "        files_all = []\n",
    "\n",
    "        for i in range(1,1001):\n",
    "            files = os.listdir(cwd + str(i))  # Get all the files in that directory\n",
    "            files_all += [str(i) + '/' + x for x in files]\n",
    "\n",
    "        encodings_dict = {}\n",
    "\n",
    "        for idx in range(len(files_all)):\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            path = cwd + files_all[idx]\n",
    "            im = PIL.Image.open(path)\n",
    "            im_resize = im.resize((224, 224))\n",
    "            if np.array(im_resize).shape == (224, 224):\n",
    "                im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "            elif np.array(im_resize).shape == (224, 224, 4):\n",
    "                im_resize = np.array(im_resize)\n",
    "                im_resize = im_resize[:, :, 0:3]\n",
    "            np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "            out = self._encoderModel.predict(np_im)\n",
    "\n",
    "            encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "    \n",
    "        with open(self._src, 'w') as outfile:\n",
    "            json.dump(encodings_dict, outfile)\n",
    "        \n",
    "    def set_src(self):\n",
    "        '''\n",
    "        Sets a hardcoded path according to user encoding type setting.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "            self._s3_path = 's3://compressedencodings/resnet50_validation_1000_pure_text.txt'\n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_simple_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_dense_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'debug':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'combined':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "            \n",
    "        \n",
    "    def get_src(self):\n",
    "        return self._src\n",
    "        \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_dense_searcher = searchEngine('ae_dense_2048')\n",
    "# ae_dense_searcher.load_encoder()\n",
    "# ae_dense_searcher.generate_encodings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1000)\n",
      "(50000, 2048)\n",
      "(50000, 3048)\n"
     ]
    }
   ],
   "source": [
    "resnet_searcher = searchEngine('resnet_1000')\n",
    "combined_searcher = searchEngine('combined')\n",
    "ae_bottleneck_searcher = searchEngine('ae_bottleneck_2048')\n",
    "ae_dense_searcher = searchEngine('ae_dense_2048')\n",
    "ae_simple_searcher = searchEngine('ae_simple_2048')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_searcher.build_annoy_forest(1000)\n",
    "combined_searcher.build_annoy_forest(1000)\n",
    "ae_bottleneck_searcher.build_annoy_forest(1000)\n",
    "ae_simple_searcher.build_annoy_forest(1000)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "resnet_searcher.build_annoy_forest(100)\n",
    "combined_searcher.build_annoy_forest(100)\n",
    "ae_bottleneck_searcher.build_annoy_forest(100)\n",
    "ae_simple_searcher.build_annoy_forest(100)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "resnet_searcher.build_annoy_forest(10)\n",
    "combined_searcher.build_annoy_forest(10)\n",
    "ae_bottleneck_searcher.build_annoy_forest(10)\n",
    "ae_simple_searcher.build_annoy_forest(10)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-00e0068a9d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'brute_force'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# combined_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ae_dense_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-c62694aa45af>\u001b[0m in \u001b[0;36msave_scores\u001b[0;34m(self, search_mode, normalized, ranks, num_classes)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnormalized\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                     dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n\u001b[0;32m--> 349\u001b[0;31m                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                                                     reshape(-1, 1)), \n\u001b[1;32m    351\u001b[0m                                                     axis = 1)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2506\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2507\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_dense_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_scores(self, search_mode, ranks = [5, 10, 20, 50]):\n",
    "    \n",
    "    score_src = search_mode + \"_\" + self.encoding_type + \"_scores.txt\"\n",
    "    \n",
    "    with open(score_src) as f:\n",
    "        loaded_scores =  json.load(f)\n",
    "\n",
    "    def map_at_rank(rank):\n",
    "\n",
    "        class_averages = []\n",
    "\n",
    "        for (k, v) in loaded_scores.items():\n",
    "            class_averages.append(np.mean(v[rank]))\n",
    "\n",
    "        return np.mean(class_averages)#, np.argsort(class_averages)[::-1]\n",
    "    \n",
    "    return map_at_rank('5'), map_at_rank('10'), map_at_rank('20')\n",
    "\n",
    "print(process_scores(resnet_searcher, 'annoy'))\n",
    "print(process_scores(combined_searcher, 'annoy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = np.random.randint(0,50000)\n",
    "\n",
    "print(search_idx)\n",
    "\n",
    "resnet_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "combined_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "\n",
    "# 18759\n",
    "# 40728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# resnet_searcher.load_encoder()\n",
    "# resnet_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# searcher1.brute_force_search_index(query_index=1600, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1593, num_results=5, show_flag=1)\n",
    "# searcher1.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=9100, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=9100, num_results=5, show_flag=1, normalized = True)\n",
    "\n",
    "searcher1.brute_force_search_index(query_index=981, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "searcher.brute_force_search_index(query_index=981, num_results=5, show_flag=1, normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.build_annoy_forest(10, 'test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searcher.annoy_search_index(query_index=601, num_results=5, show_flag=1)\n",
    "\n",
    "searcher.annoy_search_index(query_index=6016, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.annoy_search_index(query_index=600, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.distributed_search(9901, 20, 'j-3HHZFA4CQZND8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt') as f:\n",
    "    for line in f:\n",
    "        out = list(str(line).replace('[','').\n",
    "                             replace(']','').\n",
    "                             replace(',', '').\n",
    "                             replace('\"','').\n",
    "                             replace('1\\t','').\n",
    "                             replace('\\n', '').split(\" \"))\n",
    "        \n",
    "print(out[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vec.txt') as f:\n",
    "    for line in f:\n",
    "        out = line.split(\" \")\n",
    "\n",
    "out = [float(x) for x in out]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = keras.models.load_model('/Users/ChrisPenny/Downloads/AE_Bottleneck_F4_0001_Final.h5')\n",
    "\n",
    "testModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# encoderModel = keras.Model(inputs = testModel.input, \n",
    "#                            outputs = keras.layers.GlobalMaxPool2D()\n",
    "#                            (testModel.layers[-12].output))\n",
    "\n",
    "encoderModel = keras.Model(inputs = testModel.input, \n",
    "                           outputs = testModel.layers[-15].output)\n",
    "\n",
    "encoderModel.compile()\n",
    "\n",
    "encoderModel.summary()\n",
    "\n",
    "# for layer in testModel.layers:\n",
    "#     print(layer.name)\n",
    "    \n",
    "# testModel.layers[-15].name\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_url =  \"/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/9/ILSVRC2012_val_00027762.JPEG\"\n",
    "\n",
    "# query_url = \"/Users/ChrisPenny/Desktop/IMG_3657.jpg\"\n",
    "\n",
    "\n",
    "# out = testModel.predict(np_im)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(encoding[0]))\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(np_im[0]/255)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(out[0]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "# im = PIL.Image.open(query_url)\n",
    "# im_resize = im.resize((224, 224))\n",
    "# np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd += '/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "files_all = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    files = os.listdir(cwd + str(i))  # Get all the files in that directory\n",
    "    files_all += [str(i) + '/' + x for x in files]\n",
    "\n",
    "\n",
    "encodings_dict = {}\n",
    "\n",
    "for idx in range(49000, len(files_all)):\n",
    "    \n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    \n",
    "    path = cwd + files_all[idx]\n",
    "    im = PIL.Image.open(path)\n",
    "    im_resize = im.resize((224, 224))\n",
    "    if np.array(im_resize).shape == (224, 224):\n",
    "        im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "    elif np.array(im_resize).shape == (224, 224, 4):\n",
    "        im_resize = np.array(im_resize)\n",
    "        im_resize = im_resize[:, :, 0:3]\n",
    "    np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    out = self._encoderModel.predict(np_im)\n",
    "    \n",
    "    encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "    \n",
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
