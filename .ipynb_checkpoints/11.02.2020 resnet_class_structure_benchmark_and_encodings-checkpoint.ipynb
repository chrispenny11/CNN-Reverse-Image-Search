{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras.applications.resnet import decode_predictions\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=4,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create base resnet model:\n",
    "base_model = ka.ResNet50(\n",
    "                        include_top=True,\n",
    "                        weights='imagenet',\n",
    "                        input_shape = (224, 224, 3)\n",
    "                        )\n",
    "\n",
    "# Create additional model that adds 2048 layer to output:\n",
    "model = keras.Model(inputs = base_model.input, outputs = [base_model.layers[-1].output, base_model.layers[-2].output])\n",
    "\n",
    "# Define optimizer and compile:\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "base_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# View models for debug:\n",
    "# model.summary()\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image Source Directory - here we use the resnet class structure:\n",
    "directory = './ImageNet/organized_validation_resnet/'\n",
    "class_order = [str(x) for x in range(1, 1001)]\n",
    "\n",
    "# Load in resnet preprocess input function:\n",
    "resnet_preprocess = keras.applications.resnet.preprocess_input\n",
    "\n",
    "# Create ImageDataGeneratore:\n",
    "val_id_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = resnet_preprocess)\n",
    "\n",
    "# Create generator used to load validation set into memory:\n",
    "val_gen = val_id_gen.flow_from_directory(\n",
    "                                        directory, \n",
    "                                        target_size=(224, 224),\n",
    "                                        color_mode='rgb', \n",
    "                                        classes= class_order,\n",
    "                                        batch_size=1, \n",
    "                                        shuffle=False, \n",
    "                                        seed=13,\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine generator for encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.zeros((10000, 224, 224, 3))\n",
    "y_val = np.zeros((10000, 1000))\n",
    "\n",
    "# x_encoded = np.zeros((50000, 2048))\n",
    "# y_encoded = np.zeros((50000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "(10000, 1000)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "(10000, 1000)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "(10000, 1000)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "(10000, 1000)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "for z in range(1, 6):\n",
    "    for i in range(10000):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        x, y = val_gen.next()\n",
    "        x_val[i, :, :, :] = x\n",
    "        y_val[i, :] = y\n",
    "\n",
    "    # x_train, x_val, y_train, y_val = train_test_split(x_val, y_val, train_size = .75, shuffle = True)\n",
    "\n",
    "#     out = model_extra.predict(x_val)\n",
    "    out = base_model.predict(x_val)\n",
    "    \n",
    "#     print(a.shape)\n",
    "#     print(b.shape)\n",
    "#     print(c.shape)\n",
    "\n",
    "    print(out.shape)\n",
    "\n",
    "    # Add dictionary with out and actual y to dump:\n",
    "    pickle.dump( out, open( \"imagenet_val_2048_encoding_\" + str(z) + \".p\", \"wb\" ), -1)\n",
    "\n",
    "\n",
    "#     x_encoded[z:z+10000, :] = c\n",
    "#     y_encoded[z:z+10000, :] = y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out.shape)\n",
    "\n",
    "# for pred in out:\n",
    "# #     print(pred.shape)\n",
    "#     pred = pred.reshape(1, 1000)\n",
    "#     decoded = keras.applications.resnet.decode_predictions(\n",
    "#         pred, top=5\n",
    "#     )\n",
    "# #     print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out_intermediate[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # out = out_intermediate\n",
    "\n",
    "# dist_from_first = []\n",
    "# image_dict = {}\n",
    "# index = 1444\n",
    "# first_features = out[index]\n",
    "# first_image = x_val[index][:,:,:]\n",
    "# print(first_image.shape)\n",
    "\n",
    "# # hash images:\n",
    "# # for idx in range(x_val.shape[0]):\n",
    "# #     image_dict[str(out[idx])] = x_val[idx] \n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(first_image/255)\n",
    "# plt.show()\n",
    "\n",
    "# # # for i in range(400):\n",
    "# # #     if i % 25 == 0:\n",
    "# # #         print(i)\n",
    "# for idx, item in enumerate(out):\n",
    "# #     print(first_features.shape)\n",
    "# #     print(item.shape)\n",
    "#     dist_from_first.append((np.linalg.norm(first_features-item), (str(item))))\n",
    "\n",
    "# # dist_from_first.sort()\n",
    "# print(dist_from_first[0])\n",
    "\n",
    "# # for i in range(20):\n",
    "# #     plt.clf()\n",
    "# #     img = image_dict[dist_from_first[i][1]]\n",
    "# #     plt.imshow(img/255)\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
