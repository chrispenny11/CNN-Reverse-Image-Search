{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"]= 300\n",
    "mpl.rc('axes.spines',top=False,bottom=False,left=False,right=False);\n",
    "mpl.rc('axes',facecolor=(0,0,0,0),edgecolor=(0,0,0,0));\n",
    "mpl.rc(('xtick','ytick'),color=(0,0,0,0));\n",
    "import time\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "from annoy import AnnoyIndex\n",
    "import subprocess\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "from keras.applications.resnet import decode_predictions\n",
    "\n",
    "class searchEngine():\n",
    "\n",
    "    def __init__(self, encoding_user_set = 'resnet_1000'):\n",
    "\n",
    "        self.class_key = pd.read_csv('/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/imagenet_resnet_key.csv')\n",
    "        self.encoding_type = encoding_user_set\n",
    "        self.set_src()\n",
    "        self._tree_count = None\n",
    "        try:\n",
    "            self.load_database()\n",
    "        except:\n",
    "            print('Must generate encodings for this setting.')\n",
    "\n",
    "    def brute_force_search_index(self, query_index, num_results, show_flag=1, normalized=False):\n",
    "\n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Use Numpy to calculate distance values:\n",
    "        dist_to_query = []\n",
    "        if normalized == True:\n",
    "            dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                            np.array(searcher._values)/np.linalg.norm(np.array(searcher._values), axis = 1).reshape(-1, 1)), axis = 1)\n",
    "        else:\n",
    "            dist_to_query = np.linalg.norm((query_vec - np.array(self._values)), axis = 1)\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = np.argsort(dist_to_query)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "            \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "    def show_results(self, query_idx, dist_rank, num_results, query_filepath = None):\n",
    "        \n",
    "        if query_filepath == None:\n",
    "            query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "        else:\n",
    "            query_img = PIL.Image.open(query_filepath)\n",
    "\n",
    "        print(self._keys[query_idx])\n",
    "\n",
    "        concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "        for i in range(1, num_results + 1):\n",
    "            result_idx = dist_rank[i]\n",
    "            result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "            result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "            if len(np.array(result_img).shape) == 2:\n",
    "                result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "            elif np.array(result_img).shape == (224, 224, 4):\n",
    "                result_img = np.array(result_img)\n",
    "                result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "            concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "            print(self._keys[result_idx])\n",
    "\n",
    "        plt.clf()\n",
    "        plt.imshow(concat_img/255)\n",
    "        plt.show()\n",
    "        \n",
    "    def annoy_search_index(self, query_index, num_results, show_flag=1):\n",
    "        \n",
    "        # Query vector:\n",
    "        query_vec = np.array(self._values[query_index])\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, num_results+1)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "\n",
    "    def distributed_search(self, query_index, num_results, cluster_id):\n",
    "        \n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "        query_vec_str = ''\n",
    "        for elem in query_vec:\n",
    "            query_vec_str += str(elem) + ' '\n",
    "        query_vec_str = query_vec_str[:-1]\n",
    "#         print(query_vec_str)\n",
    "        \n",
    "        f = open(\"vec.txt\",\"w\")\n",
    "        f.write(query_vec_str)\n",
    "        \n",
    "#         subprocess.run(\"python3 distributed_prototype.py \" + str(self._s3_path) + \n",
    "#                        \" -r emr --cluster-id=\" + \n",
    "#                        str(cluster_id) + \n",
    "#                        \" --no-output --no-read-logs --region=us-east-2 --query=\" + \n",
    "#                        str(query_vec) + \" \" +\n",
    "#                        \" > output.txt\", shell = True)\n",
    "\n",
    "        subprocess.run(\"python3 distributed_prototype.py \" + \n",
    "                       str(self._s3_path) + \n",
    "                       \" -r emr --cluster-id=\" + \n",
    "                       str(cluster_id) + \n",
    "                       \" --no-read-logs --region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                       shell = True)\n",
    "    \n",
    "    \n",
    "#         with open('output.txt') as f:\n",
    "#             for line in f:\n",
    "#                 out = list(str(line).replace('[','').\n",
    "#                                      replace(']','').\n",
    "#                                      replace(',', '').\n",
    "#                                      replace('\"','').\n",
    "#                                      replace('1\\t','').\n",
    "#                                      replace('\\n', '').split(\" \"))\n",
    "\n",
    "#         print(out[1::2])\n",
    "        \n",
    "#         if show_flag == 1:\n",
    "#             query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "\n",
    "#             plt.clf()\n",
    "#             plt.imshow(query_img)\n",
    "#             plt.show()\n",
    "\n",
    "    def build_annoy_forest(self, tree_count, seed = 13):\n",
    "        \n",
    "        self._tree_count = tree_count\n",
    "        t = AnnoyIndex(len(self._values[0]), 'angular')\n",
    "        t.set_seed(seed)\n",
    "\n",
    "        for idx, item in enumerate(self._values):\n",
    "            t.add_item(idx, np.array(item))\n",
    "            \n",
    "        t.build(tree_count)\n",
    "        self._annoy_forest = t\n",
    "\n",
    "    def load_database(self):\n",
    "\n",
    "        with open(self._src) as f:\n",
    "            db =  json.load(f)\n",
    "\n",
    "        self._values = np.array([x for x in db.values()])\n",
    "        self._keys = list(db.keys())\n",
    "        \n",
    "        if self.encoding_type == 'combined':\n",
    "            \n",
    "            resnet_enc_norm = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(resnet_enc_norm.shape)\n",
    "            \n",
    "            self.encoding_type = 'ae_bottleneck_2048'\n",
    "            self.set_src()\n",
    "            self.encoding_type = 'combined'\n",
    "            \n",
    "            with open(self._src) as f:\n",
    "                db =  json.load(f)\n",
    "            \n",
    "            ae_enc_norm = np.array([x for x in db.values()])/np.linalg.norm(np.array([x for x in db.values()]),\n",
    "                                                                            axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(ae_enc_norm.shape)\n",
    "            \n",
    "            self._values = np.concatenate([resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "            \n",
    "            print(self._values.shape)\n",
    "        \n",
    "    def load_encoder(self):\n",
    "        '''\n",
    "        Loads the original model and uses its paramemters to compile the encoding layers.\n",
    "        \n",
    "        Only available for relevant encoding types.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000' or self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._encoderModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-2].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Simple_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = keras.layers.GlobalMaxPool2D()\n",
    "                                             (self._underlyingModel.layers[-12].output))\n",
    "            \n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Dense_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-9].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_bottleneck_2048' or self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "        elif self.encoding_type == 'combined':\n",
    "            \n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "            self._encoderModel.compile()\n",
    "            \n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                           input_shape = (224, 224, 3))  \n",
    "            \n",
    "            self._underlyingModel.compile()\n",
    "        \n",
    "        else:\n",
    "            print('No model matching that encoding type.')\n",
    "            return\n",
    "\n",
    "        self._encoderModel.compile()\n",
    "\n",
    "    def prep_image(self, path):\n",
    "    \n",
    "        im = PIL.Image.open(path)\n",
    "        im_resize = im.resize((224, 224))\n",
    "        if np.array(im_resize).shape == (224, 224):\n",
    "            im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "        elif np.array(im_resize).shape == (224, 224, 4):\n",
    "            im_resize = np.array(im_resize)\n",
    "            im_resize = im_resize[:, :, 0:3]\n",
    "        \n",
    "        return np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    def encoder_search(self, query_path, num_results, show = 1):\n",
    "        \n",
    "        np_image = self.prep_image(query_path)\n",
    "        \n",
    "        if self.encoding_type == \"combined\":\n",
    "            resnet_encoding = self._underlyingModel.predict(np_image)\n",
    "            ae_encoding = self._encoderModel.predict(np_image)\n",
    "            resnet_enc_norm = resnet_encoding/np.linalg.norm(resnet_encoding).reshape(-1, 1)\n",
    "            ae_enc_norm = ae_encoding/np.linalg.norm(ae_encoding).reshape(-1, 1)\n",
    "            query_encoding = np.concatenate([resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "        else:\n",
    "            query_encoding = self._encoderModel.predict(np_image)\n",
    "        \n",
    "        if self._tree_count == None:\n",
    "            self.build_annoy_forest(10)\n",
    "        \n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_encoding[0], num_results+1)\n",
    "\n",
    "        self.show_results(0, dist_ranking, num_results, query_filepath = query_path)\n",
    "\n",
    "#         if show == 1:\n",
    "\n",
    "#             im = PIL.Image.open(query_url)\n",
    "\n",
    "#             plt.clf()\n",
    "#             plt.imshow(im)\n",
    "#             plt.show()\n",
    "\n",
    "#             for i in range(1, num_results + 1):\n",
    "#                 result_idx = dist_ranking[i]\n",
    "#                 result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "\n",
    "#                 plt.clf()\n",
    "#                 plt.rcParams['figure.figsize'] = [12, 8]\n",
    "#                 plt.imshow(result_img)\n",
    "#                 plt.show()\n",
    "\n",
    "#                 print(self._keys[result_idx])\n",
    "            \n",
    "    def generate_reconstruction(self, image_path):\n",
    "        pass\n",
    "            \n",
    "    def save_scores(self, search_mode = 'annoy', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000):\n",
    "        '''\n",
    "        Scores encodings by ImageNet class as mean average precision.\n",
    "\n",
    "        Only valid for validation directories - otherwise leaky.\n",
    "        '''\n",
    "        \n",
    "        # Precompute normalization of each encoding:\n",
    "        # Saves a lot of runtime.\n",
    "        if normalized == True:\n",
    "            self._values_normed = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "\n",
    "        # Dictionary keeps track of scores by class:\n",
    "        score_dict = {}\n",
    "\n",
    "        for idx in range(num_classes*50):\n",
    "            \n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "                if normalized == True:\n",
    "                    dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                                    self._values_normed), \n",
    "                                                    axis = 1)\n",
    "                else:\n",
    "                    dist_to_query = np.linalg.norm(query_vec - self._values, \n",
    "                                                   axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, np.max(ranks) + 1)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Compare classes:\n",
    "            correct = 0\n",
    "            rank_idx = 0\n",
    "            # Note: First result is the image itself, so we skip it.\n",
    "            for jdx in range(1, np.max(ranks) + 1):\n",
    "\n",
    "                result_key = self._keys[dist_ranking[jdx]]\n",
    "                result_class = result_key[:result_key.find('/')]\n",
    "\n",
    "                if result_class == query_class:\n",
    "                    correct += 1\n",
    "\n",
    "                if ranks[rank_idx] == jdx:\n",
    "\n",
    "                    if query_class not in score_dict:\n",
    "                        score_dict[query_class] = {}\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "                    elif ranks[rank_idx] not in score_dict[query_class]:\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "\n",
    "                    score_dict[query_class][ranks[rank_idx]].append(correct/ranks[rank_idx])#, end_time - start_time))\n",
    "\n",
    "                    rank_idx += 1\n",
    "                \n",
    "                score_dict['time'] = end_time - start_time\n",
    "                \n",
    "        if search_mode == 'annoy':\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)             \n",
    "        else:\n",
    "            if normalized == True:\n",
    "                with open(search_mode + \"_normalized_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)        \n",
    "            else:\n",
    "                with open(search_mode + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)         \n",
    "\n",
    "#     def save_scores(self, search_mode = 'annoy', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000):\n",
    "#         '''\n",
    "#         Scores encodings by ImageNet class as mean average precision.\n",
    "\n",
    "#         Only valid for validation directories - otherwise leaky.\n",
    "#         '''\n",
    "\n",
    "#         # Dictionary keeps track of scores by class:\n",
    "#         score_dict = {}\n",
    "\n",
    "#         for idx in range(num_classes*50):\n",
    "\n",
    "#             # Query info:\n",
    "#             query_vec = self._values[idx]\n",
    "#             query_key = self._keys[idx]\n",
    "#             query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "#             # Begin timer:\n",
    "#             start_time = time.time()\n",
    "\n",
    "#             # Calculate distance values:\n",
    "#             dist_to_query = []\n",
    "\n",
    "#             if search_mode == 'brute_force':\n",
    "#                 if normalized == True:\n",
    "#                     dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "#                                                     self._values/np.linalg.norm(self._values, axis = 1).\n",
    "#                                                     reshape(-1, 1)), \n",
    "#                                                     axis = 1)\n",
    "#                 else:\n",
    "#                     dist_to_query = np.linalg.norm(query_vec - self._values, axis = 1)\n",
    "#                 # Rank by distance:    \n",
    "#                 dist_ranking = np.argsort(dist_to_query)\n",
    "#             elif search_mode == 'annoy':\n",
    "#                 dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, np.max(ranks) + 1)\n",
    "#             else:\n",
    "#                 print(\"Not a valid search mode\")\n",
    "#                 return\n",
    "\n",
    "#             # End timer:\n",
    "#             end_time = time.time()\n",
    "\n",
    "#             # Compare classes:\n",
    "#             correct = 0\n",
    "#             rank_idx = 0\n",
    "#             # Note: First result is the image itself, so we skip it.\n",
    "#             for jdx in range(1, np.max(ranks) + 1):\n",
    "\n",
    "#                 result_key = self._keys[dist_ranking[jdx]]\n",
    "#                 result_class = result_key[:result_key.find('/')]\n",
    "\n",
    "#                 if result_class == query_class:\n",
    "#                     correct += 1\n",
    "\n",
    "#                 if ranks[rank_idx] == jdx:\n",
    "\n",
    "#                     if query_class not in score_dict:\n",
    "#                         score_dict[query_class] = {}\n",
    "#                         score_dict[query_class][ranks[rank_idx]] = []\n",
    "#                     elif ranks[rank_idx] not in score_dict[query_class]:\n",
    "#                         score_dict[query_class][ranks[rank_idx]] = []\n",
    "\n",
    "#                     score_dict[query_class][ranks[rank_idx]].append(correct/ranks[rank_idx])#, end_time - start_time))\n",
    "\n",
    "#                     rank_idx += 1\n",
    "                \n",
    "#                 score_dict['time'] = end_time - start_time\n",
    "                \n",
    "#         if search_mode == 'annoy':\n",
    "#             with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "#                 json.dump(score_dict, outfile)             \n",
    "#         else:\n",
    "#             if normalized == True:\n",
    "#                 with open(search_mode + \"_normalized_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "#                     json.dump(score_dict, outfile)        \n",
    "#             else:\n",
    "#                 with open(search_mode + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "#                     json.dump(score_dict, outfile)        \n",
    "\n",
    "    def generate_encodings(self):\n",
    "        '''\n",
    "        generate_encodings\n",
    "        '''\n",
    "        \n",
    "        \n",
    "#         cwd = os.getcwd()\n",
    "#         cwd += self._image_dir\n",
    "\n",
    "        files_all = []\n",
    "        \n",
    "        if self.encoding_type != 'ae_bottleneck_2048_scaled_up' and self.encoding_type != 'resnet_1000_scaled_up':\n",
    "            for i in range(1,1001):\n",
    "                files = os.listdir(self._image_dir + str(i))  # Get all the files in that directory\n",
    "                files_all += [str(i) + '/' + x for x in files]\n",
    "        else:\n",
    "            for class_folder in self.class_key['train_id'].values:\n",
    "                \n",
    "                files = os.listdir(self._image_dir + class_folder)  # Get all the files in that directory\n",
    "                files_all += [class_folder + '/' + x for x in files]\n",
    "            \n",
    "                \n",
    "        encodings_dict = {}\n",
    "\n",
    "        for idx in range(len(files_all)):\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            \n",
    "            try:\n",
    "                path = self._image_dir + files_all[idx]\n",
    "                im = PIL.Image.open(path)\n",
    "                im_resize = im.resize((224, 224))\n",
    "                if np.array(im_resize).shape == (224, 224):\n",
    "                    im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "                elif np.array(im_resize).shape == (224, 224, 4):\n",
    "                    im_resize = np.array(im_resize)\n",
    "                    im_resize = im_resize[:, :, 0:3]\n",
    "                np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "                out = self._encoderModel.predict(np_im)\n",
    "\n",
    "                encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "            except:\n",
    "                print('Skipping one image.')\n",
    "    \n",
    "        with open(self._src, 'w') as outfile:\n",
    "            json.dump(encodings_dict, outfile)\n",
    "        \n",
    "    def set_src(self):\n",
    "        '''\n",
    "        Sets a hardcoded path according to user encoding type setting.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "            self._s3_path = 's3://compressedencodings/resnet50_validation_1000_pure_text.txt'\n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_simple_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_dense_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'combined':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'debug':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "        elif self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/resnet50_scaled_up_1000.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_scaled_up_2048.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "\n",
    "        \n",
    "    def get_src(self):\n",
    "        return self._src\n",
    "        \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must generate encodings for this setting.\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n",
      "374000\n",
      "375000\n",
      "376000\n",
      "377000\n",
      "378000\n",
      "379000\n",
      "380000\n",
      "381000\n",
      "382000\n",
      "383000\n",
      "384000\n",
      "385000\n",
      "386000\n",
      "387000\n",
      "388000\n",
      "389000\n",
      "390000\n",
      "391000\n",
      "392000\n",
      "393000\n",
      "394000\n",
      "395000\n",
      "396000\n",
      "397000\n",
      "398000\n",
      "399000\n",
      "400000\n",
      "401000\n",
      "402000\n",
      "403000\n",
      "404000\n",
      "405000\n",
      "406000\n",
      "407000\n",
      "408000\n",
      "409000\n",
      "410000\n",
      "411000\n"
     ]
    }
   ],
   "source": [
    "# searcher = searchEngine('ae_bottleneck_2048_scaled_up')\n",
    "searcher = searchEngine('resnet_1000_scaled_up')\n",
    "\n",
    "searcher.load_encoder()\n",
    "\n",
    "searcher.generate_encodings()\n",
    "\n",
    "# ae_dense_searcher.build_annoy_forest(10)\n",
    "\n",
    "# ae_dense_searcher.annoy_search_index(10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(searcher.class_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae_dense_searcher.load_encoder()\n",
    "ae_dense_searcher.encoder_search(\"\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_searcher = searchEngine('resnet_1000')\n",
    "combined_searcher = searchEngine('combined')\n",
    "ae_bottleneck_searcher = searchEngine('ae_bottleneck_2048')\n",
    "ae_dense_searcher = searchEngine('ae_bottleneck_2048')\n",
    "ae_simple_searcher = searchEngine('ae_simple_2048')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_searcher.build_annoy_forest(10000)\n",
    "combined_searcher.build_annoy_forest(10000)\n",
    "ae_bottleneck_searcher.build_annoy_forest(10000)\n",
    "ae_dense_searcher.build_annoy_forest(10000)\n",
    "ae_simple_searcher.build_annoy_forest(10000)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "resnet_searcher.build_annoy_forest(1000)\n",
    "combined_searcher.build_annoy_forest(1000)\n",
    "ae_bottleneck_searcher.build_annoy_forest(1000)\n",
    "ae_dense_searcher.build_annoy_forest(1000)\n",
    "ae_simple_searcher.build_annoy_forest(1000)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "resnet_searcher.build_annoy_forest(100)\n",
    "combined_searcher.build_annoy_forest(100)\n",
    "ae_bottleneck_searcher.build_annoy_forest(100)\n",
    "ae_dense_searcher.build_annoy_forest(100)\n",
    "ae_simple_searcher.build_annoy_forest(100)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "resnet_searcher.build_annoy_forest(10)\n",
    "combined_searcher.build_annoy_forest(10)\n",
    "ae_bottleneck_searcher.build_annoy_forest(10)\n",
    "ae_dense_searcher.build_annoy_forest(10)\n",
    "ae_simple_searcher.build_annoy_forest(10)\n",
    "\n",
    "resnet_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_scores(self, search_mode, ranks = [5, 10, 20, 50]):\n",
    "    \n",
    "    score_src = search_mode + \"_\" + self.encoding_type + \"_scores.txt\"\n",
    "    \n",
    "    with open(score_src) as f:\n",
    "        loaded_scores =  json.load(f)\n",
    "\n",
    "    def map_at_rank(rank):\n",
    "\n",
    "        class_averages = []\n",
    "\n",
    "        for (k, v) in loaded_scores.items():\n",
    "            class_averages.append(np.mean(v[rank]))\n",
    "\n",
    "        return np.mean(class_averages)#, np.argsort(class_averages)[::-1]\n",
    "    \n",
    "    return map_at_rank('5'), map_at_rank('10'), map_at_rank('20')\n",
    "\n",
    "print(process_scores(resnet_searcher, 'annoy'))\n",
    "print(process_scores(combined_searcher, 'annoy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = np.random.randint(0,50000)\n",
    "\n",
    "print(search_idx)\n",
    "\n",
    "resnet_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "combined_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "\n",
    "# 18759\n",
    "# 40728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# resnet_searcher.load_encoder()\n",
    "# resnet_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# searcher1.brute_force_search_index(query_index=1600, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1593, num_results=5, show_flag=1)\n",
    "# searcher1.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=9100, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=9100, num_results=5, show_flag=1, normalized = True)\n",
    "\n",
    "searcher1.brute_force_search_index(query_index=981, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "searcher.brute_force_search_index(query_index=981, num_results=5, show_flag=1, normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.build_annoy_forest(10, 'test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searcher.annoy_search_index(query_index=601, num_results=5, show_flag=1)\n",
    "\n",
    "searcher.annoy_search_index(query_index=6016, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.annoy_search_index(query_index=600, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.distributed_search(9901, 20, 'j-3HHZFA4CQZND8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt') as f:\n",
    "    for line in f:\n",
    "        out = list(str(line).replace('[','').\n",
    "                             replace(']','').\n",
    "                             replace(',', '').\n",
    "                             replace('\"','').\n",
    "                             replace('1\\t','').\n",
    "                             replace('\\n', '').split(\" \"))\n",
    "        \n",
    "print(out[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vec.txt') as f:\n",
    "    for line in f:\n",
    "        out = line.split(\" \")\n",
    "\n",
    "out = [float(x) for x in out]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = keras.models.load_model('/Users/ChrisPenny/Downloads/AE_Bottleneck_F4_0001_Final.h5')\n",
    "\n",
    "testModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# encoderModel = keras.Model(inputs = testModel.input, \n",
    "#                            outputs = keras.layers.GlobalMaxPool2D()\n",
    "#                            (testModel.layers[-12].output))\n",
    "\n",
    "encoderModel = keras.Model(inputs = testModel.input, \n",
    "                           outputs = testModel.layers[-15].output)\n",
    "\n",
    "encoderModel.compile()\n",
    "\n",
    "encoderModel.summary()\n",
    "\n",
    "# for layer in testModel.layers:\n",
    "#     print(layer.name)\n",
    "    \n",
    "# testModel.layers[-15].name\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_url =  \"/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/9/ILSVRC2012_val_00027762.JPEG\"\n",
    "\n",
    "# query_url = \"/Users/ChrisPenny/Desktop/IMG_3657.jpg\"\n",
    "\n",
    "\n",
    "# out = testModel.predict(np_im)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(encoding[0]))\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(np_im[0]/255)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(out[0]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "# im = PIL.Image.open(query_url)\n",
    "# im_resize = im.resize((224, 224))\n",
    "# np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd += '/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "files_all = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    files = os.listdir(cwd + str(i))  # Get all the files in that directory\n",
    "    files_all += [str(i) + '/' + x for x in files]\n",
    "\n",
    "\n",
    "encodings_dict = {}\n",
    "\n",
    "for idx in range(49000, len(files_all)):\n",
    "    \n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    \n",
    "    path = cwd + files_all[idx]\n",
    "    im = PIL.Image.open(path)\n",
    "    im_resize = im.resize((224, 224))\n",
    "    if np.array(im_resize).shape == (224, 224):\n",
    "        im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "    elif np.array(im_resize).shape == (224, 224, 4):\n",
    "        im_resize = np.array(im_resize)\n",
    "        im_resize = im_resize[:, :, 0:3]\n",
    "    np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    out = self._encoderModel.predict(np_im)\n",
    "    \n",
    "    encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "    \n",
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlyingModel = keras.models.load_model(\n",
    "                        './models/AE_Dense_F4_0001_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlyingModel.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
