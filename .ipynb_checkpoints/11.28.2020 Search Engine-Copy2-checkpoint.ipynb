{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"]= 300\n",
    "mpl.rc('axes.spines',top=False,bottom=False,left=False,right=False);\n",
    "mpl.rc('axes',facecolor=(0,0,0,0),edgecolor=(0,0,0,0));\n",
    "mpl.rc(('xtick','ytick'),color=(0,0,0,0));\n",
    "import time\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "from annoy import AnnoyIndex\n",
    "import subprocess\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "from keras.applications.resnet import decode_predictions\n",
    "\n",
    "class searchEngine():\n",
    "\n",
    "    def __init__(self, encoding_user_set = 'resnet_1000', combined_weight = 1):\n",
    "\n",
    "        self.class_key = pd.read_csv('/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/imagenet_resnet_key.csv')\n",
    "        self.encoding_type = encoding_user_set\n",
    "        self.set_src()\n",
    "        self._tree_count = None\n",
    "        self._combined_resnet_weight = 0.3\n",
    "        self._combined_weight = combined_weight\n",
    "        try:\n",
    "            self.load_database()\n",
    "        except:\n",
    "            print('Must generate encodings for this setting.')\n",
    "\n",
    "    def brute_force_search_index(self, query_index, num_results, show_flag=1, normalized=False):\n",
    "\n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Use Numpy to calculate distance values:\n",
    "        dist_to_query = []\n",
    "        if normalized == True:\n",
    "            dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                            np.array(searcher._values)/np.linalg.norm(np.array(searcher._values), axis = 1).reshape(-1, 1)), axis = 1)\n",
    "        else:\n",
    "            dist_to_query = np.linalg.norm((query_vec - np.array(self._values)), axis = 1)\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = np.argsort(dist_to_query)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "            \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "    def show_results(self, query_idx, dist_rank, num_results, query_filepath = None):\n",
    "        \n",
    "        if query_filepath == None:\n",
    "            query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "        else:\n",
    "            query_img = PIL.Image.open(query_filepath)\n",
    "\n",
    "        print(self._keys[query_idx])\n",
    "        \n",
    "        \n",
    "\n",
    "        concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "        for i in range(1, num_results + 1):\n",
    "            result_idx = dist_rank[i]\n",
    "            result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "            result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "            if len(np.array(result_img).shape) == 2:\n",
    "                result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "            elif np.array(result_img).shape == (224, 224, 4):\n",
    "                result_img = np.array(result_img)\n",
    "                result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "            concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "            print(self._keys[result_idx])\n",
    "\n",
    "        plt.clf()\n",
    "        plt.imshow(concat_img/255)\n",
    "        plt.show()\n",
    "        \n",
    "    def annoy_search_index(self, query_index, num_results, show_flag=1):\n",
    "        \n",
    "        # Query vector:\n",
    "        query_vec = np.array(self._values[query_index])\n",
    "\n",
    "        # Query key:\n",
    "        query_key = self._keys[query_index]\n",
    "\n",
    "        # Begin timer:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, num_results+1)\n",
    "\n",
    "        # End timer:\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "\n",
    "    def distributed_search(self, query_index, num_results, cluster_id = 'local'):\n",
    "\n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "        query_vec_str = ''\n",
    "        for elem in query_vec:\n",
    "            query_vec_str += str(elem) + ' '\n",
    "        query_vec_str = query_vec_str[:-1]\n",
    "    #         print(query_vec_str)\n",
    "\n",
    "        f = open(\"vec.txt\",\"w\")\n",
    "        f.write(query_vec_str)\n",
    "\n",
    "        if cluster_id == 'local':\n",
    "            print('Running locally')\n",
    "            subprocess.run(\"python3 distributed_prototype_local.py \" + \n",
    "                           str(self._src) + \n",
    "                           \" -r local \" + \n",
    "                           \"--region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                           shell = True)\n",
    "        else:\n",
    "\n",
    "            subprocess.run(\"python3 distributed_prototype.py \" + \n",
    "                           str(self._s3_path) + \n",
    "                           \" -r emr --cluster-id=\" + \n",
    "                           str(cluster_id) + \n",
    "                           \" --no-read-logs --region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                           shell = True)\n",
    "\n",
    "\n",
    "#         with open('output.txt') as f:\n",
    "#             for line in f:\n",
    "#                 out = list(str(line).replace('[','').\n",
    "#                                      replace(']','').\n",
    "#                                      replace(',', '').\n",
    "#                                      replace('\"','').\n",
    "#                                      replace('1\\t','').\n",
    "#                                      replace('\\n', '').split(\" \"))\n",
    "\n",
    "# #         print(out[1::2])\n",
    "#         out_paths = out[1::2]\n",
    "#         if show_flag == 1:\n",
    "#         for item in out[1::2]:\n",
    "#             img = PIL.Image.open(searcher._image_dir + item)\n",
    "\n",
    "#             plt.clf()\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#         query_img = PIL.Image.open(self._image_dir + out_paths[0])\n",
    "\n",
    "#         concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "#         for i in range(1, num_results + 1):\n",
    "#             result_path = out_paths[i]\n",
    "#             result_img = PIL.Image.open(self._image_dir + result_path)\n",
    "#             result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "#             if len(np.array(result_img).shape) == 2:\n",
    "#                 result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "#             elif np.array(result_img).shape == (224, 224, 4):\n",
    "#                 result_img = np.array(result_img)\n",
    "#                 result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "#             concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "#         plt.clf()\n",
    "#         plt.imshow(concat_img/255)\n",
    "#         plt.show()\n",
    "        \n",
    "    def build_annoy_forest(self, tree_count, seed = 13):\n",
    "        \n",
    "        self._tree_count = tree_count\n",
    "        t = AnnoyIndex(len(self._values[0]), 'euclidean')\n",
    "        t.set_seed(seed)\n",
    "\n",
    "        for idx, item in enumerate(self._values):\n",
    "            t.add_item(idx, np.array(item))\n",
    "            \n",
    "        t.build(tree_count)\n",
    "        self._annoy_forest = t\n",
    "\n",
    "    def load_database(self):\n",
    "\n",
    "        with open(self._src) as f:\n",
    "            db =  json.load(f)\n",
    "\n",
    "        self._values = np.array([x for x in db.values()])\n",
    "        self._keys = list(db.keys())\n",
    "        \n",
    "        if self.encoding_type == 'combined':\n",
    "            \n",
    "            resnet_enc_norm = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(resnet_enc_norm.shape)\n",
    "            \n",
    "            self.encoding_type = 'ae_bottleneck_2048'\n",
    "            self.set_src()\n",
    "            self.encoding_type = 'combined'\n",
    "            \n",
    "            with open(self._src) as f:\n",
    "                db =  json.load(f)\n",
    "            \n",
    "            ae_enc_norm = np.array([x for x in db.values()])/np.linalg.norm(np.array([x for x in db.values()]),\n",
    "                                                                            axis = 1).reshape(-1, 1)\n",
    "            \n",
    "#             print(ae_enc_norm.shape)\n",
    "            \n",
    "            self._values = np.concatenate([self._combined_weight*resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "            \n",
    "            print(self._values.shape)\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_1000_normalized':\n",
    "            \n",
    "            self._values = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "        \n",
    "    def load_encoder(self):\n",
    "        '''\n",
    "        Loads the original model and uses its paramemters to compile the encoding layers.\n",
    "        \n",
    "        Only available for relevant encoding types.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000' or self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._encoderModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-2].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Simple_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = keras.layers.GlobalMaxPool2D()\n",
    "                                             (self._underlyingModel.layers[-12].output))\n",
    "            \n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Dense_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-9].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_bottleneck_2048' or self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "        elif self.encoding_type == 'combined':\n",
    "            \n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "            self._encoderModel.compile()\n",
    "            \n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                           input_shape = (224, 224, 3))  \n",
    "            \n",
    "            self._underlyingModel.compile()\n",
    "            \n",
    "            print('Combined encoders loaded.')\n",
    "        \n",
    "        else:\n",
    "            print('No model matching that encoding type.')\n",
    "            return\n",
    "\n",
    "        self._encoderModel.compile()\n",
    "\n",
    "    def prep_image(self, path):\n",
    "    \n",
    "        im = PIL.Image.open(path)\n",
    "        im_resize = im.resize((224, 224))\n",
    "        if np.array(im_resize).shape == (224, 224):\n",
    "            im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "        elif np.array(im_resize).shape == (224, 224, 4):\n",
    "            im_resize = np.array(im_resize)\n",
    "            im_resize = im_resize[:, :, 0:3]\n",
    "        \n",
    "        return np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    def encoder_search(self, query_path, num_results, show = 1):\n",
    "        \n",
    "        np_image = self.prep_image(query_path)\n",
    "        \n",
    "        if self.encoding_type == \"combined\":\n",
    "            resnet_encoding = self._underlyingModel.predict(np_image)\n",
    "            ae_encoding = self._encoderModel.predict(np_image)\n",
    "            resnet_enc_norm = resnet_encoding/np.linalg.norm(resnet_encoding).reshape(-1, 1)\n",
    "            ae_enc_norm = ae_encoding/np.linalg.norm(ae_encoding).reshape(-1, 1)\n",
    "            query_encoding = np.concatenate([self._combined_weight*resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "        else:\n",
    "            query_encoding = self._encoderModel.predict(np_image)\n",
    "        \n",
    "#         if self._tree_count == None:\n",
    "#             self.build_annoy_forest(10)\n",
    "        \n",
    "#         print(query_encoding[0])\n",
    "        # Rank by distance:\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_encoding[0], num_results+1)\n",
    "\n",
    "        self.show_results(0, dist_ranking, num_results, query_filepath = query_path)\n",
    "            \n",
    "    def generate_reconstruction(self, image_path):\n",
    "        '''\n",
    "        Generate a reconstructed images using an autoencoder model.\n",
    "        \n",
    "        Note that in order to show parity between the input and the reconstructed image,\n",
    "        we plot the resized 224 x 224 x 3 image in both cases:\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type not in {\"ae_bottleneck_2048\", \"ae_dense_2048\", \"ae_simple_2048\"}:\n",
    "            print(\"Reconstruction is only available for autoencoder models.\")\n",
    "        else:\n",
    "            np_image = self.prep_image(image_path)\n",
    "            \n",
    "            plt.clf()\n",
    "            plt.imshow(np_image[0]/255)\n",
    "            plt.show()\n",
    "            \n",
    "            reconstructed_image = self._underlyingModel(np_image)\n",
    "        \n",
    "            plt.clf()\n",
    "            plt.imshow(reconstructed_image[0]/255)\n",
    "            plt.show()\n",
    "            \n",
    "    def save_scores(self, search_mode = 'annoy', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000):\n",
    "        '''\n",
    "        Scores encodings by ImageNet class as mean average precision.\n",
    "\n",
    "        Only valid for validation directories - otherwise leaky.\n",
    "        '''\n",
    "        \n",
    "        # Precompute normalization of each encoding:\n",
    "        # Saves a lot of runtime.\n",
    "        if normalized == True:\n",
    "            self._values_normed = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "\n",
    "        # Dictionary keeps track of scores by class:\n",
    "        score_dict = {}\n",
    "\n",
    "        for idx in range(num_classes*50):\n",
    "            \n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "\n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "                if normalized == True:\n",
    "                    dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                                    self._values_normed), \n",
    "                                                    axis = 1)\n",
    "                else:\n",
    "                    dist_to_query = np.linalg.norm(query_vec - self._values, \n",
    "                                                   axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, np.max(ranks) + 1)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Compare classes:\n",
    "            correct = 0\n",
    "            rank_idx = 0\n",
    "            # Note: First result is the image itself, so we skip it.\n",
    "            for jdx in range(1, np.max(ranks) + 1):\n",
    "\n",
    "                result_key = self._keys[dist_ranking[jdx]]\n",
    "                result_class = result_key[:result_key.find('/')]\n",
    "\n",
    "                if result_class == query_class:\n",
    "                    correct += 1\n",
    "\n",
    "                if ranks[rank_idx] == jdx:\n",
    "\n",
    "                    if query_class not in score_dict:\n",
    "                        score_dict[query_class] = {}\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "                    elif ranks[rank_idx] not in score_dict[query_class]:\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "\n",
    "                    score_dict[query_class][ranks[rank_idx]].append(correct/ranks[rank_idx])#, end_time - start_time))\n",
    "\n",
    "                    rank_idx += 1\n",
    "                \n",
    "                score_dict['time'] = end_time - start_time\n",
    "                \n",
    "        if search_mode == 'annoy' and self._combined_weight == 1:\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)\n",
    "        elif search_mode == 'annoy' and self._combined_weight == 0.5:\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_0.5_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)\n",
    "        else:\n",
    "            if normalized == True:\n",
    "                with open(search_mode + \"_normalized_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)        \n",
    "            else:\n",
    "                with open(search_mode + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)         \n",
    "\n",
    "\n",
    "    def score_runtimes(self, search_mode, c_id = 'j-22JGSV587G1E1'):\n",
    "        \n",
    "        runtimes = []\n",
    "        rand_index = np.random.randint(0, 50000, (1000,))\n",
    "\n",
    "        for i in range(100):\n",
    "            idx = rand_index[i]\n",
    "            \n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "            \n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "\n",
    "                dist_to_query = np.linalg.norm(query_vec - self._values, \n",
    "                                               axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, 50)\n",
    "            elif search_mode == 'distributed':\n",
    "                self.distributed_search(idx, 50, cluster_id = c_id)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "            \n",
    "            runtimes.append(end_time - start_time)\n",
    "        return np.mean(runtimes), np.var(runtimes)\n",
    "            \n",
    "        \n",
    "    def generate_encodings(self):\n",
    "        '''\n",
    "        Generates encodings based on user supplied encoding type and loaded encoder.\n",
    "        \n",
    "        Be careful when using this functionality - it will overwrite existing encodings.\n",
    "        '''\n",
    "\n",
    "        files_all = []\n",
    "        \n",
    "        if self.encoding_type != 'ae_bottleneck_2048_scaled_up' and self.encoding_type != 'resnet_1000_scaled_up':\n",
    "            for i in range(1,1001):\n",
    "                files = os.listdir(self._image_dir + str(i))  # Get all the files in that directory\n",
    "                files_all += [str(i) + '/' + x for x in files]\n",
    "        else:\n",
    "            for class_folder in self.class_key['train_id'].values:\n",
    "                \n",
    "                files = os.listdir(self._image_dir + class_folder)  # Get all the files in that directory\n",
    "                files_all += [class_folder + '/' + x for x in files]\n",
    "            \n",
    "                \n",
    "        encodings_dict = {}\n",
    "\n",
    "        for idx in range(len(files_all)):\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            \n",
    "            try:\n",
    "                path = self._image_dir + files_all[idx]\n",
    "                im = PIL.Image.open(path)\n",
    "                im_resize = im.resize((224, 224))\n",
    "                if np.array(im_resize).shape == (224, 224):\n",
    "                    im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "                elif np.array(im_resize).shape == (224, 224, 4):\n",
    "                    im_resize = np.array(im_resize)\n",
    "                    im_resize = im_resize[:, :, 0:3]\n",
    "                np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "                out = self._encoderModel.predict(np_im)\n",
    "\n",
    "                encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "            except:\n",
    "                print('Skipping one image.')\n",
    "    \n",
    "        with open(self._src, 'w') as outfile:\n",
    "            json.dump(encodings_dict, outfile)\n",
    "        \n",
    "    def set_src(self):\n",
    "        '''\n",
    "        Sets a hardcoded path according to user encoding type setting.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "            self._s3_path = 's3://compressedencodings/resnet50_validation_1000_pure_text.txt'\n",
    "        elif self.encoding_type == 'resnet_1000_normalized':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_simple_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_dense_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'combined':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'debug':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/resnet50_scaled_up_1000.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_scaled_up_2048.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "\n",
    "        \n",
    "    def get_src(self):\n",
    "        return self._src\n",
    "        \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1000)\n",
      "(50000, 3048)\n",
      "(50000, 1000)\n",
      "(50000, 3048)\n"
     ]
    }
   ],
   "source": [
    "resnet_1000_searcher = searchEngine('resnet_1000')\n",
    "resnet_1000_normalized_searcher = searchEngine('resnet_1000_normalized')\n",
    "resnet_2048_searcher = searchEngine('resnet_2048')\n",
    "combined_searcher = searchEngine('combined')\n",
    "combined_weighted_searcher = searchEngine('combined', combined_weight = 0.5)\n",
    "ae_bottleneck_searcher = searchEngine('ae_bottleneck_2048')\n",
    "ae_dense_searcher = searchEngine('ae_dense_2048')\n",
    "ae_simple_searcher = searchEngine('ae_simple_2048')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_1000_searcher.build_annoy_forest(1000)\n",
    "resnet_1000_normalized_searcher.build_annoy_forest(1000)\n",
    "resnet_2048_searcher.build_annoy_forest(1000)\n",
    "combined_searcher.build_annoy_forest(1000)\n",
    "combined_weighted_searcher.build_annoy_forest(1000)\n",
    "ae_bottleneck_searcher.build_annoy_forest(1000)\n",
    "ae_dense_searcher.build_annoy_forest(1000)\n",
    "ae_simple_searcher.build_annoy_forest(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined encoders loaded.\n",
      "Combined encoders loaded.\n"
     ]
    }
   ],
   "source": [
    "resnet_1000_searcher.load_encoder()\n",
    "resnet_2048_searcher.load_encoder()\n",
    "combined_searcher.load_encoder()\n",
    "combined_weighted_searcher.load_encoder()\n",
    "ae_bottleneck_searcher.load_encoder()\n",
    "ae_dense_searcher.load_encoder()\n",
    "ae_simple_searcher.load_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 5)\n",
    "\n",
    "# # resnet_2048_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# resnet_2048_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "# resnet_2048_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 5)\n",
    "\n",
    "# # combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 5)\n",
    "\n",
    "# # combined_weighted_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# combined_weighted_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "# combined_weighted_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 5)\n",
    "\n",
    "\n",
    "\n",
    "# # ae_bottleneck_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# ae_bottleneck_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "\n",
    "# # ae_dense_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# ae_dense_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "\n",
    "# # ae_simple_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 5)\n",
    "# ae_simple_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 5)\n",
    "\n",
    "query_paths = [\"/Users/ChrisPenny/Downloads/fxslide3.jpg\",\n",
    "               \"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\",\n",
    "               \"/Users/ChrisPenny/Desktop/IMG_3657.jpg\",\n",
    "               \"/Users/ChrisPenny/Downloads/F-35A_flight_(cropped).jpg\",\n",
    "               \"/Users/ChrisPenny/Downloads/1583454329186.jpeg\"\n",
    "              ]\n",
    "\n",
    "for query_img_path in query_paths:\n",
    "    resnet_1000_searcher.encoder_search(query_img_path, 5)\n",
    "    resnet_2048_searcher.encoder_search(query_img_path, 5)\n",
    "    combined_searcher.encoder_search(query_img_path, 5)\n",
    "    combined_weighted_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_bottleneck_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_dense_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_simple_searcher.encoder_search(query_img_path, 5)\n",
    "    \n",
    "#     \"/Users/ChrisPenny/Downloads/F-35A_flight_(cropped).jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1583454329186.jpeg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/180219103122-zanzibar-and-its-islands---mnemba-a-view-from-the-sky-mnemba-island-lodge.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images.jpeg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/coca-cola-coke-coca-cola.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0 copy.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0.jpg\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Timing Analysis:\n",
    "# resnet_1000_searcher.build_annoy_forest(10)\n",
    "# resnet_1000_searcher.score_runtimes('annoy')\n",
    "# resnet_1000_searcher.build_annoy_forest(100)\n",
    "# resnet_1000_searcher.score_runtimes('annoy')\n",
    "# resnet_1000_searcher.build_annoy_forest(1000)\n",
    "# resnet_1000_searcher.score_runtimes('annoy')\n",
    "\n",
    "# resnet_1000_searcher.score_runtimes('brute_force')\n",
    "\n",
    "resnet_1000_searcher.score_runtimes('distributed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_1000_searcher.score_runtimes('distributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ae_bottleneck_searcher.load_encoder()\n",
    "# ae_dense_searcher.load_encoder()\n",
    "# ae_simple_searcher.load_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ae_bottleneck_searcher.generate_reconstruction(\"/Users/ChrisPenny/Downloads/images (2).jpeg\")\n",
    "\n",
    "# ae_bottleneck_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 4.59.10 PM.png\")\n",
    "# ae_dense_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 4.59.10 PM.png\")\n",
    "# ae_simple_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 4.59.10 PM.png\")\n",
    "\n",
    "# ae_bottleneck_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.06.56 PM.png\")\n",
    "# ae_dense_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.06.56 PM.png\")\n",
    "# ae_simple_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.06.56 PM.png\")\n",
    "\n",
    "# ae_bottleneck_searcher.generate_reconstruction(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\")\n",
    "# ae_dense_searcher.generate_reconstruction(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\")\n",
    "# ae_simple_searcher.generate_reconstruction(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\")\n",
    "\n",
    "ae_bottleneck_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.16.02 PM.png\")\n",
    "ae_dense_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.16.02 PM.png\")\n",
    "ae_simple_searcher.generate_reconstruction(\"/Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.16.02 PM.png\")\n",
    "\n",
    "\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\", 10)\n",
    "# /Users/ChrisPenny/Desktop/Screen Shot 2020-11-28 at 6.16.02 PM.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def distributed_search(searcher, query_index, num_results, cluster_id = 'local'):\n",
    "\n",
    "#     # Query vector:\n",
    "#     query_vec = searcher._values[query_index]\n",
    "#     query_vec_str = ''\n",
    "#     for elem in query_vec:\n",
    "#         query_vec_str += str(elem) + ' '\n",
    "#     query_vec_str = query_vec_str[:-1]\n",
    "# #         print(query_vec_str)\n",
    "\n",
    "#     f = open(\"vec.txt\",\"w\")\n",
    "#     f.write(query_vec_str)\n",
    "\n",
    "#     if cluster_id == 'local':\n",
    "#         print('Running locally')\n",
    "#         subprocess.run(\"python3 distributed_prototype_local.py \" + \n",
    "#                        str(searcher._src) + \n",
    "#                        \" -r local \" + \n",
    "#                        \"--region=us-east-2 --query=vec.txt > output.txt\", \n",
    "#                        shell = True)\n",
    "#     else:\n",
    "\n",
    "#         subprocess.run(\"python3 distributed_prototype.py \" + \n",
    "#                        str(searcher._s3_path) + \n",
    "#                        \" -r emr --cluster-id=\" + \n",
    "#                        str(cluster_id) + \n",
    "#                        \" --no-read-logs --region=us-east-2 --query=vec.txt > output.txt\", \n",
    "#                        shell = True)\n",
    "\n",
    "\n",
    "#     with open('output.txt') as f:\n",
    "#         for line in f:\n",
    "#             out = list(str(line).replace('[','').\n",
    "#                                  replace(']','').\n",
    "#                                  replace(',', '').\n",
    "#                                  replace('\"','').\n",
    "#                                  replace('1\\t','').\n",
    "#                                  replace('\\n', '').split(\" \"))\n",
    "\n",
    "# #         print(out[1::2])\n",
    "#         out_paths = out[1::2]\n",
    "# #         if show_flag == 1:\n",
    "# #         for item in out[1::2]:\n",
    "# #             img = PIL.Image.open(searcher._image_dir + item)\n",
    "\n",
    "# #             plt.clf()\n",
    "# #             plt.imshow(img)\n",
    "# #             plt.show()\n",
    "#         query_img = PIL.Image.open(searcher._image_dir + out_paths[0])\n",
    "\n",
    "#         concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "#         for i in range(1, num_results + 1):\n",
    "#             result_path = out_paths[i]\n",
    "#             result_img = PIL.Image.open(searcher._image_dir + result_path)\n",
    "#             result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "#             if len(np.array(result_img).shape) == 2:\n",
    "#                 result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "#             elif np.array(result_img).shape == (224, 224, 4):\n",
    "#                 result_img = np.array(result_img)\n",
    "#                 result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "#             concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "#         plt.clf()\n",
    "#         plt.imshow(concat_img/255)\n",
    "#         plt.show()\n",
    "\n",
    "# # distributed_search(resnet_1000_searcher, 55, 5)\n",
    "# distributed_search(resnet_1000_searcher, 55, 5, cluster_id = 'j-1GZDDMO5LWTZ7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_1000_searcher.load_encoder()\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/7MileBeach-2013-HiRes.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/F-35A_flight_(cropped).jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1583454329186.jpeg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/180219103122-zanzibar-and-its-islands---mnemba-a-view-from-the-sky-mnemba-island-lodge.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images.jpeg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/coca-cola-coke-coca-cola.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0 copy.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0.jpg\", 10)\n",
    "resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (2) copy.jpeg\", 10)\n",
    "resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (2).jpeg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Van-Gogh-starry-night-print2.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/cb4b3ea65d0b315e153116ecd9043070.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/366ad6eb4f5923b3148f2ae7616f1225.jpg\", 10)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Dogs+and+Puppies+%27Mona+Lisa+Pet%27+Graphic+Art+Print+on+Wrapped+Canvas.jpg\", 5)\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (1).jpeg\", 5)\n",
    "\n",
    "# /Users/ChrisPenny/Downloads/images (1).jpeg\n",
    "\n",
    "# combined_searcher.load_encoder()\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/7MileBeach-2013-HiRes.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/F-35A_flight_(cropped).jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1583454329186.jpeg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/180219103122-zanzibar-and-its-islands---mnemba-a-view-from-the-sky-mnemba-island-lodge.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images.jpeg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Smashburger-recipe-120219.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/coca-cola-coke-coca-cola.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0 copy.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0.jpg\", 10)\n",
    "combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (2) copy.jpeg\", 10)\n",
    "combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (2).jpeg\", 10)\n",
    "\n",
    "# /Users/ChrisPenny/Downloads/images (2).jpeg\n",
    "\n",
    "# /Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0.jpg\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Parking-lot-photo-e1580338586257.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/IMG_2943_0.jpeg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/920x920.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/best-time-to-see-the-eagles-in-red-wing-mn-e1573503128460.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Starry-Night-canvas-Vincent-van-Gogh-New-1889.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Van-Gogh-starry-night-print2.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/cb4b3ea65d0b315e153116ecd9043070.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/366ad6eb4f5923b3148f2ae7616f1225.jpg\", 10)\n",
    "\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/fa7ffb75d3f227e86171003113a26bd3.jpg\", 10)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/41d1giSZH1L.jpg\", 5)\n",
    "# /Users/ChrisPenny/Downloads/41d1giSZH1L.jpg\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/Dogs+and+Puppies+%27Mona+Lisa+Pet%27+Graphic+Art+Print+on+Wrapped+Canvas.jpg\", 5)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/images (1).jpeg\", 5)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/il_570xN.590011994_dmmh.jpg\", 5)\n",
    "# /Users/ChrisPenny/Downloads/il_570xN.590011994_dmmh.jpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_1000_searcher.build_annoy_forest(10000)\n",
    "# resnet_2048_searcher.build_annoy_forest(10000)\n",
    "# combined_searcher.build_annoy_forest(10000)\n",
    "# ae_bottleneck_searcher.build_annoy_forest(10000)\n",
    "# ae_dense_searcher.build_annoy_forest(10000)\n",
    "# ae_simple_searcher.build_annoy_forest(10000)\n",
    "\n",
    "# resnet_1000_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_2048_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_1000_searcher.build_annoy_forest(1000)\n",
    "# resnet_1000_normalized_searcher.build_annoy_forest(1000)\n",
    "# resnet_2048_searcher.build_annoy_forest(1000)\n",
    "# combined_searcher.build_annoy_forest(1000)\n",
    "# combined_weighted_searcher.build_annoy_forest(1000)\n",
    "# ae_bottleneck_searcher.build_annoy_forest(1000)\n",
    "# ae_dense_searcher.build_annoy_forest(1000)\n",
    "# ae_simple_searcher.build_annoy_forest(1000)\n",
    "\n",
    "# resnet_1000_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_1000_normalized_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_2048_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_weighted_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_1000_searcher.build_annoy_forest(100)\n",
    "# resnet_1000_normalized_searcher.build_annoy_forest(100)\n",
    "# resnet_2048_searcher.build_annoy_forest(100)\n",
    "# combined_searcher.build_annoy_forest(100)\n",
    "# combined_weighted_searcher.build_annoy_forest(100)\n",
    "# ae_bottleneck_searcher.build_annoy_forest(100)\n",
    "# ae_dense_searcher.build_annoy_forest(100)\n",
    "# ae_simple_searcher.build_annoy_forest(100)\n",
    "\n",
    "# resnet_1000_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_1000_normalized_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_2048_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_weighted_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_1000_searcher.build_annoy_forest(10)\n",
    "# resnet_1000_normalized_searcher.build_annoy_forest(10)\n",
    "# resnet_2048_searcher.build_annoy_forest(10)\n",
    "# combined_searcher.build_annoy_forest(10)\n",
    "# combined_weighted_searcher.build_annoy_forest(10)\n",
    "# ae_bottleneck_searcher.build_annoy_forest(10)\n",
    "# ae_dense_searcher.build_annoy_forest(10)\n",
    "# ae_simple_searcher.build_annoy_forest(10)\n",
    "\n",
    "# resnet_1000_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_1000_normalized_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# resnet_2048_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_weighted_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_dense_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = True, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "\n",
    "# resnet_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# combined_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_bottleneck_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)\n",
    "# ae_simple_searcher.save_scores(search_mode = 'brute_force', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_1000_searcher.build_annoy_forest(10000)\n",
    "combined_searcher.build_annoy_forest(1000)\n",
    "# ae_bottleneck_searcher.build_annoy_forest(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_1000_searcher.load_encoder()\n",
    "# resnet_1000_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 20)\n",
    "\n",
    "# ae_bottleneck_searcher.load_encoder()\n",
    "# ae_bottleneck_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)\n",
    "\n",
    "combined_searcher.load_encoder()\n",
    "combined_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 20)\n",
    "# combined_searcher.encoder_search(\"/Users/ChrisPenny/Downloads/7MileBeach-2013-HiRes.jpg\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_searcher.save_scores(search_mode = 'annoy', ranks = [5, 10, 20, 50], num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_scores(self, search_mode, ranks = [5, 10, 20, 50]):\n",
    "    \n",
    "    score_src = search_mode + \"_\" + self.encoding_type + \"_scores.txt\"\n",
    "    \n",
    "    with open(score_src) as f:\n",
    "        loaded_scores =  json.load(f)\n",
    "\n",
    "    def map_at_rank(rank):\n",
    "\n",
    "        class_averages = []\n",
    "\n",
    "        for (k, v) in loaded_scores.items():\n",
    "            class_averages.append(np.mean(v[rank]))\n",
    "\n",
    "        return np.mean(class_averages)#, np.argsort(class_averages)[::-1]\n",
    "    \n",
    "    return map_at_rank('5'), map_at_rank('10'), map_at_rank('20')\n",
    "\n",
    "print(process_scores(resnet_searcher, 'annoy'))\n",
    "print(process_scores(combined_searcher, 'annoy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_idx = np.random.randint(0,50000)\n",
    "\n",
    "print(search_idx)\n",
    "\n",
    "resnet_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "combined_searcher.brute_force_search_index(query_index=search_idx, num_results=5, show_flag=1)\n",
    "\n",
    "# 18759\n",
    "# 40728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# resnet_searcher.load_encoder()\n",
    "# resnet_searcher.encoder_search(\"/Users/ChrisPenny/Desktop/IMG_3657.jpg\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# searcher1.brute_force_search_index(query_index=1600, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1593, num_results=5, show_flag=1)\n",
    "# searcher1.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "# searcher.brute_force_search_index(query_index=1605, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=45608, num_results=5, show_flag=1)\n",
    "\n",
    "# searcher1.brute_force_search_index(query_index=9100, num_results=5, show_flag=1)\n",
    "# print('-----')\n",
    "# searcher.brute_force_search_index(query_index=9100, num_results=5, show_flag=1, normalized = True)\n",
    "\n",
    "searcher1.brute_force_search_index(query_index=981, num_results=5, show_flag=1)\n",
    "print('-----')\n",
    "searcher.brute_force_search_index(query_index=981, num_results=5, show_flag=1, normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.build_annoy_forest(10, 'test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searcher.annoy_search_index(query_index=601, num_results=5, show_flag=1)\n",
    "\n",
    "searcher.annoy_search_index(query_index=6016, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.annoy_search_index(query_index=600, num_results=5, show_flag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.distributed_search(9901, 20, 'j-3HHZFA4CQZND8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.txt') as f:\n",
    "    for line in f:\n",
    "        out = list(str(line).replace('[','').\n",
    "                             replace(']','').\n",
    "                             replace(',', '').\n",
    "                             replace('\"','').\n",
    "                             replace('1\\t','').\n",
    "                             replace('\\n', '').split(\" \"))\n",
    "        \n",
    "print(out[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vec.txt') as f:\n",
    "    for line in f:\n",
    "        out = line.split(\" \")\n",
    "\n",
    "out = [float(x) for x in out]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = keras.models.load_model('/Users/ChrisPenny/Downloads/AE_Bottleneck_F4_0001_Final.h5')\n",
    "\n",
    "testModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# encoderModel = keras.Model(inputs = testModel.input, \n",
    "#                            outputs = keras.layers.GlobalMaxPool2D()\n",
    "#                            (testModel.layers[-12].output))\n",
    "\n",
    "encoderModel = keras.Model(inputs = testModel.input, \n",
    "                           outputs = testModel.layers[-15].output)\n",
    "\n",
    "encoderModel.compile()\n",
    "\n",
    "encoderModel.summary()\n",
    "\n",
    "# for layer in testModel.layers:\n",
    "#     print(layer.name)\n",
    "    \n",
    "# testModel.layers[-15].name\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_url =  \"/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/9/ILSVRC2012_val_00027762.JPEG\"\n",
    "\n",
    "# query_url = \"/Users/ChrisPenny/Desktop/IMG_3657.jpg\"\n",
    "\n",
    "\n",
    "# out = testModel.predict(np_im)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(encoding[0]))\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(np_im[0]/255)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.clf()\n",
    "# plt.imshow(out[0]/255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "# im = PIL.Image.open(query_url)\n",
    "# im_resize = im.resize((224, 224))\n",
    "# np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd += '/ImageNet/organized_validation_resnet/'\n",
    "\n",
    "files_all = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    files = os.listdir(cwd + str(i))  # Get all the files in that directory\n",
    "    files_all += [str(i) + '/' + x for x in files]\n",
    "\n",
    "\n",
    "encodings_dict = {}\n",
    "\n",
    "for idx in range(49000, len(files_all)):\n",
    "    \n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    \n",
    "    path = cwd + files_all[idx]\n",
    "    im = PIL.Image.open(path)\n",
    "    im_resize = im.resize((224, 224))\n",
    "    if np.array(im_resize).shape == (224, 224):\n",
    "        im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "    elif np.array(im_resize).shape == (224, 224, 4):\n",
    "        im_resize = np.array(im_resize)\n",
    "        im_resize = im_resize[:, :, 0:3]\n",
    "    np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    out = self._encoderModel.predict(np_im)\n",
    "    \n",
    "    encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "    \n",
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt', 'w') as outfile:\n",
    "    json.dump(encodings_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlyingModel = keras.models.load_model(\n",
    "                        './models/AE_Dense_F4_0001_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlyingModel.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
