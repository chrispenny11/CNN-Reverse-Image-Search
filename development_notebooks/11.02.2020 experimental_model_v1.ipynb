{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "# from tensorflow.keras.keras_preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_model = ka.ResNet50(\n",
    "                        include_top=True,\n",
    "                        weights='imagenet',#,\n",
    "#                         classes=2,\n",
    "                        input_shape = (224, 224, 3)\n",
    "                        )\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# # base_model_add_layers = keras.Model(inputs = base_model.input, outputs = base_model.output)\n",
    "# # out_1 = keras.layers.GlobalAvgPool2D()(base_model.output)\n",
    "# # out_1 = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "# x = keras.layers.Flatten()(base_model.layers[-2].output)\n",
    "x = keras.layers.Dense(1024, activation='sigmoid')(base_model.layers[-2].output)\n",
    "# x = keras.layers.Dense(1000, activation='sigmoid')(x)\n",
    "out_1 = keras.layers.Dense(1000, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs = base_model.input, outputs = out_1)#, base_model.output, base_model.layers[-2].output])\n",
    "model_extra = keras.Model(inputs = model.input, outputs = [model.layers[-1].output, model.layers[-2].output, model.layers[-3].output])\n",
    "# opt = keras.optimizers.SGD(lr = 0.0001)\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "# base_model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "model_extra.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# model.summary()\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = './ImageNet/organized_validation/'\n",
    "\n",
    "# data_batches = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"categorical\",\n",
    "# #     class_names=None,\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=1,\n",
    "#     image_size=(224, 224),\n",
    "#     shuffle=True,\n",
    "#     seed=13,\n",
    "# #     validation_split=None,\n",
    "# #     subset=None,\n",
    "#     interpolation=\"bilinear\"\n",
    "# #     follow_links=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38000 images belonging to 1000 classes.\n",
      "Found 12000 images belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "directory = './ImageNet/organized_validation_resnet/'\n",
    "\n",
    "resnet_preprocess = keras.applications.resnet.preprocess_input\n",
    "\n",
    "val_id_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = resnet_preprocess,\n",
    "                                                          validation_split = 0.25)\n",
    "# val_gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "# val_id_gen = tensorflow.keras.preprocessing.image.ImageDataGenerator()\n",
    "# val_gen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_gen = val_id_gen.flow_from_directory(\n",
    "    directory, \n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb', \n",
    "    classes=None,\n",
    "    class_mode='categorical', \n",
    "    batch_size=8, \n",
    "    shuffle=True, \n",
    "    seed=13,\n",
    "    subset='training',\n",
    "#     save_to_dir=None, \n",
    "#     save_prefix='', \n",
    "#     save_format='png', f\n",
    "#     ollow_links=False,\n",
    "#     subset=None, \n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "val_gen = val_id_gen.flow_from_directory(\n",
    "    directory, \n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb', \n",
    "    classes=None,\n",
    "    class_mode='categorical', \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    seed=13,\n",
    "    subset='validation',\n",
    "#     save_to_dir=None, \n",
    "#     save_prefix='', \n",
    "#     save_format='png', f\n",
    "#     ollow_links=False,\n",
    "#     subset=None, \n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "# next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 396/4750 [=>............................] - ETA: 44:22 - loss: 12.5520 - accuracy: 0.0019"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, validation_data = val_gen, epochs = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val = np.zeros((10000, 224, 224, 3))\n",
    "# y_val = np.zeros((10000, 1000))\n",
    "\n",
    "# x_encoded = np.zeros((50000, 2048))\n",
    "# y_encoded = np.zeros((50000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(1, 6):\n",
    "    for i in range(10000):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        x, y = val_gen.next()\n",
    "        x_val[i, :, :, :] = x\n",
    "        y_val[i, :] = y\n",
    "\n",
    "    # x_train, x_val, y_train, y_val = train_test_split(x_val, y_val, train_size = .75, shuffle = True)\n",
    "\n",
    "    out = model_extra.predict(x_val)\n",
    "    \n",
    "#     print(a.shape)\n",
    "#     print(b.shape)\n",
    "#     print(c.shape)\n",
    "\n",
    "    \n",
    "    pickle.dump( out, open( \"imagenet_val_1000_encoding_\" + str(z) + \".p\", \"wb\" ) )\n",
    "\n",
    "\n",
    "#     x_encoded[z:z+10000, :] = c\n",
    "#     y_encoded[z:z+10000, :] = y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out_intermediate[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = out_intermediate\n",
    "\n",
    "dist_from_first = []\n",
    "image_dict = {}\n",
    "index = 1444\n",
    "first_features = out[2][index]\n",
    "first_image = x_val[index][:,:,:]\n",
    "print(first_image.shape)\n",
    "\n",
    "# hash images:\n",
    "for idx in range(x_val.shape[0]):\n",
    "    image_dict[str(out[2][idx])] = x_val[idx] \n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(first_image/255)\n",
    "plt.show()\n",
    "\n",
    "# for i in range(400):\n",
    "#     if i % 25 == 0:\n",
    "#         print(i)\n",
    "for idx, item in enumerate(out[2]):\n",
    "    dist_from_first.append((np.linalg.norm(first_features-item), (str(item))))\n",
    "\n",
    "dist_from_first.sort()\n",
    "# print(dist_from_first)\n",
    "\n",
    "for i in range(20):\n",
    "    plt.clf()\n",
    "    img = image_dict[dist_from_first[i][1]]\n",
    "    plt.imshow(img/255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
