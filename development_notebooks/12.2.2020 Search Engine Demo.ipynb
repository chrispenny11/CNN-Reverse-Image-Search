{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"]= 300\n",
    "mpl.rc('axes.spines',top=False,bottom=False,left=False,right=False);\n",
    "mpl.rc('axes',facecolor=(0,0,0,0),edgecolor=(0,0,0,0));\n",
    "mpl.rc(('xtick','ytick'),color=(0,0,0,0));\n",
    "import time\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "from annoy import AnnoyIndex\n",
    "import subprocess\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.applications as ka\n",
    "from keras.applications.resnet import decode_predictions\n",
    "\n",
    "class searchEngine():\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self, encoding_user_set = 'resnet_1000', combined_weight = 1):\n",
    "\n",
    "        self.class_key = pd.read_csv('/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/imagenet_resnet_key.csv')\n",
    "        self.encoding_type = encoding_user_set\n",
    "        self.set_src()\n",
    "        self._tree_count = None\n",
    "        self._combined_resnet_weight = 0.3\n",
    "        self._combined_weight = combined_weight\n",
    "        try:\n",
    "            self.load_database()\n",
    "        except:\n",
    "            print('Must generate encodings for this setting.')\n",
    "            \n",
    "    ## Search By Index ##\n",
    "\n",
    "    def brute_force_search_index(self, query_index, num_results, show_flag=True, normalized=False):\n",
    "        '''\n",
    "        Performs a brute force search using a numerical index corresponding to one of the 50k images in the\n",
    "        validation set.  If show_flag is set to true, visual results are returned.\n",
    "        \n",
    "        Search is implemented as vectorized numpy operation to take Euclidean distance followed by numpy\n",
    "        argsort.\n",
    "        \n",
    "        Inputs:\n",
    "        -query_index: Integer 0-49,999\n",
    "        -num_results: Integer, number of results to return.  Note that the original image is the first result\n",
    "        and will be omitted.\n",
    "        -show_flag: True/false indicator determines if results are shown or simply processed (used in scoring)\n",
    "        -normalized: True/false indicator of whether or not or not normalization is performed in brute force \n",
    "        Euclidean search. Note that for certain encodings normalization is applied when the load_database method\n",
    "        is called.\n",
    "        '''\n",
    "        \n",
    "        query_vec = self._values[query_index]\n",
    "\n",
    "        if normalized == True:\n",
    "            dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                            np.array(searcher._values)/np.linalg.norm(np.array(searcher._values), axis = 1).reshape(-1, 1)), axis = 1)\n",
    "        else:\n",
    "            dist_to_query = np.linalg.norm((query_vec - np.array(self._values)), axis = 1)\n",
    "\n",
    "        dist_ranking = np.argsort(dist_to_query)\n",
    "            \n",
    "        if show_flag == 1:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "            \n",
    "    def annoy_search_index(self, query_index, num_results, show_flag=True):\n",
    "        '''\n",
    "        Performs a brute force search using a numerical index corresponding to one of the 50k images in the\n",
    "        validation set.  If show_flag is set to true, visual results are returned.\n",
    "        \n",
    "        NOTE: Must call the build_annoy_forest method prior to using.\n",
    "        \n",
    "        Search is implemented using ANNOY module.\n",
    "        See: https://github.com/spotify/annoy\n",
    "        \n",
    "        Inputs:\n",
    "        -query_index: integer 0-49,999\n",
    "        -num_results: Integer, number of results to return.  Note that the original image is often the first \n",
    "        result and will be omitted.\n",
    "        -show_flag: true/false indicator determines if results are shown or simply processed (used in scoring)\n",
    "        '''\n",
    "        \n",
    "        query_vec = np.array(self._values[query_index])\n",
    "\n",
    "        dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, num_results+1)\n",
    "        \n",
    "        if show_flag == True:\n",
    "            self.show_results(query_index, dist_ranking, num_results)\n",
    "\n",
    "    def show_results(self, query_idx, dist_rank, num_results, query_filepath = None):\n",
    "        '''\n",
    "        Concatenates the query image and search results into a single image and plots in a figure.\n",
    "        \n",
    "        Additionally prints class results for the images, including the query, in order.\n",
    "        '''\n",
    "        \n",
    "        if query_filepath == None:\n",
    "            query_img = PIL.Image.open(self._image_dir + self._keys[query_idx])\n",
    "        else:\n",
    "            query_img = PIL.Image.open(query_filepath)\n",
    "\n",
    "        class_code = int(self._keys[query_idx][:self._keys[query_idx].find('/')])\n",
    "        \n",
    "        if query_filepath == None:\n",
    "            print(self.class_key[self.class_key['resnet_class'] == class_code]['resnet_desc'].values[0])\n",
    "\n",
    "        concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "        for i in range(1, num_results + 1):\n",
    "            result_idx = dist_rank[i]\n",
    "            result_img = PIL.Image.open(self._image_dir + self._keys[result_idx])\n",
    "            result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "            if len(np.array(result_img).shape) == 2:\n",
    "                result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "            elif np.array(result_img).shape == (224, 224, 4):\n",
    "                result_img = np.array(result_img)\n",
    "                result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "            concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "            class_code = int(self._keys[result_idx][:self._keys[result_idx].find('/')])\n",
    "            \n",
    "            print(self.class_key[self.class_key['resnet_class'] == class_code]['resnet_desc'].values[0])\n",
    "\n",
    "\n",
    "        plt.clf()\n",
    "        plt.imshow(concat_img/255)\n",
    "        plt.show()\n",
    "        \n",
    "    def distributed_search(self, query_index, num_results, cluster_id = 'local'):\n",
    "        '''\n",
    "        Performs a distributed force search using a numerical index corresponding to one of the 50k \n",
    "        images in the validation set.\n",
    "        \n",
    "\n",
    "        \n",
    "        Inputs:\n",
    "        -query_index: integer 0-49,999\n",
    "        -num_results: integer, number of results to return\n",
    "        -cluster_id: true/false indicator determines if results are shown or simply processed (used in scoring)\n",
    "        '''\n",
    "\n",
    "        # Query vector:\n",
    "        query_vec = self._values[query_index]\n",
    "        query_vec_str = ''\n",
    "        for elem in query_vec:\n",
    "            query_vec_str += str(elem) + ' '\n",
    "        query_vec_str = query_vec_str[:-1]\n",
    "    #         print(query_vec_str)\n",
    "\n",
    "        f = open(\"vec.txt\",\"w\")\n",
    "        f.write(query_vec_str)\n",
    "\n",
    "        if cluster_id == 'local':\n",
    "            print('Running locally')\n",
    "            subprocess.run(\"python3 distributed_prototype_local.py \" + \n",
    "                           str(self._src) + \n",
    "                           \" -r local \" + \n",
    "                           \"--region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                           shell = True)\n",
    "        else:\n",
    "\n",
    "            subprocess.run(\"python3 distributed_prototype.py \" + \n",
    "                           str(self._s3_path) + \n",
    "                           \" -r emr --cluster-id=\" + \n",
    "                           str(cluster_id) + \n",
    "                           \" --no-read-logs --region=us-east-2 --query=vec.txt > output.txt\", \n",
    "                           shell = True)\n",
    "\n",
    "\n",
    "#         with open('output.txt') as f:\n",
    "#             for line in f:\n",
    "#                 out = list(str(line).replace('[','').\n",
    "#                                      replace(']','').\n",
    "#                                      replace(',', '').\n",
    "#                                      replace('\"','').\n",
    "#                                      replace('1\\t','').\n",
    "#                                      replace('\\n', '').split(\" \"))\n",
    "\n",
    "# #         print(out[1::2])\n",
    "#         out_paths = out[1::2]\n",
    "#         if show_flag == 1:\n",
    "#         for item in out[1::2]:\n",
    "#             img = PIL.Image.open(searcher._image_dir + item)\n",
    "\n",
    "#             plt.clf()\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#         query_img = PIL.Image.open(self._image_dir + out_paths[0])\n",
    "\n",
    "#         concat_img = np.array(query_img.resize((int((600/query_img.height)*query_img.width), 600)))\n",
    "\n",
    "#         for i in range(1, num_results + 1):\n",
    "#             result_path = out_paths[i]\n",
    "#             result_img = PIL.Image.open(self._image_dir + result_path)\n",
    "#             result_img = result_img.resize((int((600/result_img.height)*result_img.width), 600))\n",
    "\n",
    "#             if len(np.array(result_img).shape) == 2:\n",
    "#                 result_img = np.stack([result_img, result_img, result_img], axis = -1)\n",
    "#             elif np.array(result_img).shape == (224, 224, 4):\n",
    "#                 result_img = np.array(result_img)\n",
    "#                 result_img = result_img[:, :, 0:3]\n",
    "\n",
    "\n",
    "#             concat_img = np.concatenate([concat_img, np.zeros((600, 60, 3)), result_img], axis = 1)\n",
    "\n",
    "#         plt.clf()\n",
    "#         plt.imshow(concat_img/255)\n",
    "#         plt.show()\n",
    "        \n",
    "    def build_annoy_forest(self, tree_count, seed = 13):\n",
    "        '''\n",
    "        Builds an annoy forest ensemble in main memory.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self._tree_count = tree_count\n",
    "        \n",
    "        t = AnnoyIndex(len(self._values[0]), 'euclidean')\n",
    "        \n",
    "        t.set_seed(seed)\n",
    "\n",
    "        for idx, item in enumerate(self._values):\n",
    "            t.add_item(idx, np.array(item))\n",
    "            \n",
    "        t.build(tree_count)\n",
    "        \n",
    "        self._annoy_forest = t\n",
    "\n",
    "    def load_database(self):\n",
    "\n",
    "        with open(self._src) as f:\n",
    "            db =  json.load(f)\n",
    "\n",
    "        self._values = np.array([x for x in db.values()])\n",
    "        self._keys = list(db.keys())\n",
    "        \n",
    "        if self.encoding_type == 'combined':\n",
    "            \n",
    "            resnet_enc_norm = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "            print(resnet_enc_norm.shape)\n",
    "            \n",
    "            self.encoding_type = 'ae_bottleneck_2048'\n",
    "            self.set_src()\n",
    "            self.encoding_type = 'combined'\n",
    "            \n",
    "            with open(self._src) as f:\n",
    "                db =  json.load(f)\n",
    "            \n",
    "            ae_enc_norm = np.array([x for x in db.values()])/np.linalg.norm(np.array([x for x in db.values()]),\n",
    "                                                                            axis = 1).reshape(-1, 1)\n",
    "            \n",
    "#             print(ae_enc_norm.shape)\n",
    "            \n",
    "            self._values = np.concatenate([self._combined_weight*resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "            \n",
    "            print(self._values.shape)\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_1000_normalized':\n",
    "            \n",
    "            self._values = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "            \n",
    "        \n",
    "    def load_encoder(self):\n",
    "        '''\n",
    "        Loads the original model and uses its paramemters to compile the encoding layers.\n",
    "        \n",
    "        Only available for relevant encoding types.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000' or self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._encoderModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "            \n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                             input_shape = (224, 224, 3))\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-2].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Simple_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = keras.layers.GlobalMaxPool2D()\n",
    "                                             (self._underlyingModel.layers[-12].output))\n",
    "            \n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Dense_F4_0001_Final.h5')\n",
    "\n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input, \n",
    "                                             outputs = self._underlyingModel.layers[-9].output)\n",
    "            \n",
    "        elif self.encoding_type == 'ae_bottleneck_2048' or self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "        elif self.encoding_type == 'combined':\n",
    "            \n",
    "            self._underlyingModel = keras.models.load_model(\n",
    "                                    './models/AE_Bottleneck_F4_0001_Final.h5')\n",
    "    \n",
    "            self._encoderModel = keras.Model(inputs = self._underlyingModel.input,\n",
    "                                             outputs = self._underlyingModel.layers[-15].output)\n",
    "        \n",
    "            self._encoderModel.compile()\n",
    "            \n",
    "            self._underlyingModel = ka.ResNet50(weights='imagenet',\n",
    "                                           input_shape = (224, 224, 3))  \n",
    "            \n",
    "            self._underlyingModel.compile()\n",
    "            \n",
    "            print('Combined encoders loaded.')\n",
    "        \n",
    "        else:\n",
    "            print('No model matching that encoding type.')\n",
    "            return\n",
    "\n",
    "        self._encoderModel.compile()\n",
    "\n",
    "    def prep_image(self, path):\n",
    "        '''\n",
    "        Prepares an input image for use in the encoder_search method.\n",
    "        '''\n",
    "    \n",
    "        im = PIL.Image.open(path)\n",
    "        im_resize = im.resize((224, 224))\n",
    "        if np.array(im_resize).shape == (224, 224):\n",
    "            im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "        elif np.array(im_resize).shape == (224, 224, 4):\n",
    "            im_resize = np.array(im_resize)\n",
    "            im_resize = im_resize[:, :, 0:3]\n",
    "        \n",
    "        return np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "    \n",
    "    def encoder_search(self, query_path, num_results, show = 1):\n",
    "        \n",
    "        np_image = self.prep_image(query_path)\n",
    "        \n",
    "        if self.encoding_type == \"combined\":\n",
    "            resnet_encoding = self._underlyingModel.predict(np_image)\n",
    "            ae_encoding = self._encoderModel.predict(np_image)\n",
    "            resnet_enc_norm = resnet_encoding/np.linalg.norm(resnet_encoding).reshape(-1, 1)\n",
    "            ae_enc_norm = ae_encoding/np.linalg.norm(ae_encoding).reshape(-1, 1)\n",
    "            query_encoding = np.concatenate([self._combined_weight*resnet_enc_norm, ae_enc_norm], axis = 1)\n",
    "        else:\n",
    "            query_encoding = self._encoderModel.predict(np_image)\n",
    "\n",
    "        dist_to_query = np.linalg.norm((query_encoding[0] - self._values), axis = 1)\n",
    "        dist_ranking = np.argsort(dist_to_query)\n",
    "\n",
    "        self.show_results(0, dist_ranking, num_results, query_filepath = query_path)\n",
    "            \n",
    "    def generate_reconstruction(self, image_path):\n",
    "        '''\n",
    "        Generate a reconstructed images using an autoencoder model.\n",
    "        \n",
    "        Note that in order to show parity between the input and the reconstructed image,\n",
    "        we plot the resized 224 x 224 x 3 image in both cases:\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type not in {\"ae_bottleneck_2048\", \"ae_dense_2048\", \"ae_simple_2048\"}:\n",
    "            print(\"Reconstruction is only available for autoencoder models.\")\n",
    "        else:\n",
    "            np_image = self.prep_image(image_path)\n",
    "            \n",
    "            plt.clf()\n",
    "            plt.imshow(np_image[0]/255)\n",
    "            plt.show()\n",
    "            \n",
    "            reconstructed_image = self._underlyingModel(np_image)\n",
    "        \n",
    "            plt.clf()\n",
    "            plt.imshow(reconstructed_image[0]/255)\n",
    "            plt.show()\n",
    "            \n",
    "    def save_scores(self, search_mode = 'annoy', normalized = False, ranks = [5, 10, 20, 50], num_classes=1000, sample = False, sample_size = 10000):\n",
    "        '''\n",
    "        Scores encodings by ImageNet class as mean average precision.\n",
    "\n",
    "        Only valid for validation directories - otherwise leaky.\n",
    "        '''\n",
    "        \n",
    "        # Precompute normalization of each encoding:\n",
    "        # Saves a lot of runtime.\n",
    "        if normalized == True:\n",
    "            self._values_normed = self._values/np.linalg.norm(self._values, axis = 1).reshape(-1, 1)\n",
    "\n",
    "        # Dictionary keeps track of scores by class:\n",
    "        score_dict = {}\n",
    "\n",
    "        if sample == True:\n",
    "            rand_index = np.random.randint(0, 50000, (sample_size,))\n",
    "        else:\n",
    "            rand_index = range(50000)\n",
    "            \n",
    "        for ct, idx in enumerate(rand_index):\n",
    "            \n",
    "            if ct % 1000 == 0:\n",
    "                print(ct)\n",
    "\n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "                if normalized == True:\n",
    "                    dist_to_query = np.linalg.norm((query_vec/np.linalg.norm(query_vec) - \n",
    "                                                    self._values_normed), \n",
    "                                                    axis = 1)\n",
    "                else:\n",
    "                    dist_to_query = np.linalg.norm(query_vec - self._values, \n",
    "                                                   axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, np.max(ranks) + 1)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Compare classes:\n",
    "            correct = 0\n",
    "            rank_idx = 0\n",
    "            # Note: First result is the image itself, so we skip it.\n",
    "            for jdx in range(1, np.max(ranks) + 1):\n",
    "\n",
    "                result_key = self._keys[dist_ranking[jdx]]\n",
    "                result_class = result_key[:result_key.find('/')]\n",
    "\n",
    "                if result_class == query_class:\n",
    "                    correct += 1\n",
    "\n",
    "                if ranks[rank_idx] == jdx:\n",
    "\n",
    "                    if query_class not in score_dict:\n",
    "                        score_dict[query_class] = {}\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "                    elif ranks[rank_idx] not in score_dict[query_class]:\n",
    "                        score_dict[query_class][ranks[rank_idx]] = []\n",
    "\n",
    "                    score_dict[query_class][ranks[rank_idx]].append(correct/ranks[rank_idx])#, end_time - start_time))\n",
    "\n",
    "                    rank_idx += 1\n",
    "                \n",
    "                score_dict['time'] = end_time - start_time\n",
    "                \n",
    "        if search_mode == 'annoy' and self._combined_weight == 1:\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)\n",
    "        elif search_mode == 'annoy' and self._combined_weight == 0.4:\n",
    "            with open(search_mode + \"_\" + str(self._tree_count) + \"_\" + self.encoding_type + \"_0.4_scores.txt\", 'w') as outfile:\n",
    "                json.dump(score_dict, outfile)\n",
    "        else:\n",
    "            if normalized == True:\n",
    "                with open(search_mode + \"_normalized_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)\n",
    "            elif self._combined_weight == 0.4:\n",
    "                with open(search_mode + \"_\" + self.encoding_type + \"_0.4_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)\n",
    "            else:\n",
    "                with open(search_mode + \"_\" + self.encoding_type + \"_scores.txt\", 'w') as outfile:\n",
    "                    json.dump(score_dict, outfile)         \n",
    "\n",
    "\n",
    "    def score_runtimes(self, search_mode, c_id = 'j-22JGSV587G1E1'):\n",
    "        \n",
    "        runtimes = []\n",
    "        rand_index = np.random.randint(0, 50000, (50000,))\n",
    "\n",
    "        for i in range(50000):\n",
    "            idx = rand_index[i]\n",
    "            \n",
    "            # Query info:\n",
    "            query_vec = self._values[idx]\n",
    "            query_key = self._keys[idx]\n",
    "            query_class = query_key[:query_key.find('/')]\n",
    "\n",
    "            # Calculate distance values:\n",
    "            dist_to_query = []\n",
    "            \n",
    "            # Begin timer:\n",
    "            start_time = time.time()\n",
    "\n",
    "            if search_mode == 'brute_force':\n",
    "\n",
    "                dist_to_query = np.linalg.norm((query_vec - self._values), \n",
    "                                               axis = 1)\n",
    "                # Rank by distance:    \n",
    "                dist_ranking = np.argsort(dist_to_query)\n",
    "            elif search_mode == 'annoy':\n",
    "                dist_ranking = self._annoy_forest.get_nns_by_vector(query_vec, 50)\n",
    "            elif search_mode == 'distributed':\n",
    "                self.distributed_search(idx, 50, cluster_id = c_id)\n",
    "            else:\n",
    "                print(\"Not a valid search mode\")\n",
    "                return\n",
    "\n",
    "            # End timer:\n",
    "            end_time = time.time()\n",
    "            \n",
    "            runtimes.append(end_time - start_time)\n",
    "        return np.mean(runtimes), np.var(runtimes)\n",
    "            \n",
    "        \n",
    "    def generate_encodings(self):\n",
    "        '''\n",
    "        Generates encodings based on user supplied encoding type and loaded encoder.\n",
    "        \n",
    "        Be careful when using this functionality - it will overwrite existing encodings.\n",
    "        '''\n",
    "\n",
    "        files_all = []\n",
    "        \n",
    "        if self.encoding_type != 'ae_bottleneck_2048_scaled_up' and self.encoding_type != 'resnet_1000_scaled_up':\n",
    "            for i in range(1,1001):\n",
    "                files = os.listdir(self._image_dir + str(i))  # Get all the files in that directory\n",
    "                files_all += [str(i) + '/' + x for x in files]\n",
    "        else:\n",
    "            for class_folder in self.class_key['train_id'].values:\n",
    "                \n",
    "                files = os.listdir(self._image_dir + class_folder)  # Get all the files in that directory\n",
    "                files_all += [class_folder + '/' + x for x in files]\n",
    "            \n",
    "                \n",
    "        encodings_dict = {}\n",
    "\n",
    "        for idx in range(len(files_all)):\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            \n",
    "            try:\n",
    "                path = self._image_dir + files_all[idx]\n",
    "                im = PIL.Image.open(path)\n",
    "                im_resize = im.resize((224, 224))\n",
    "                if np.array(im_resize).shape == (224, 224):\n",
    "                    im_resize = np.stack([im_resize, im_resize, im_resize], axis = -1)\n",
    "                elif np.array(im_resize).shape == (224, 224, 4):\n",
    "                    im_resize = np.array(im_resize)\n",
    "                    im_resize = im_resize[:, :, 0:3]\n",
    "                np_im = np.array(im_resize).reshape((1, 224, 224, 3))\n",
    "\n",
    "                out = self._encoderModel.predict(np_im)\n",
    "\n",
    "                encodings_dict[files_all[idx]] = list([float(x) for x in out[0]])\n",
    "            except:\n",
    "                print('Skipping one image.')\n",
    "    \n",
    "        with open(self._src, 'w') as outfile:\n",
    "            json.dump(encodings_dict, outfile)\n",
    "        \n",
    "    def set_src(self):\n",
    "        '''\n",
    "        Sets a hardcoded path according to user encoding type setting.\n",
    "        '''\n",
    "        \n",
    "        if self.encoding_type == 'resnet_1000':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "            self._s3_path = 's3://compressedencodings/resnet50_validation_1000_pure_text.txt'\n",
    "        elif self.encoding_type == 'resnet_1000_normalized':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'resnet_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_simple_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_simple_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_dense_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_dense_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'combined':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/validation_pretrained_resnet/resnet50_validation_1000.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'debug':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/DEBUG_ae_bottleneck_validation_2048.txt'\n",
    "            self._image_dir = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/ImageNet/organized_validation_resnet/'\n",
    "        elif self.encoding_type == 'resnet_1000_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/resnet50_scaled_up_1000.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "        elif self.encoding_type == 'ae_bottleneck_2048_scaled_up':\n",
    "            self._src = '/Users/ChrisPenny/Documents/MPCS53112/project_dir/encodings/ae_bottleneck_scaled_up_2048.txt'\n",
    "            self._image_dir = '/Volumes/Samsung_T5/ImageNet/torrented_version/ILSVRC2012_img_train/'\n",
    "\n",
    "        \n",
    "    def get_src(self):\n",
    "        return self._src\n",
    "        \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1000)\n",
      "(50000, 3048)\n",
      "(50000, 1000)\n",
      "(50000, 3048)\n"
     ]
    }
   ],
   "source": [
    "resnet_1000_searcher = searchEngine('resnet_1000')\n",
    "resnet_1000_normalized_searcher = searchEngine('resnet_1000_normalized')\n",
    "resnet_2048_searcher = searchEngine('resnet_2048')\n",
    "combined_searcher = searchEngine('combined')\n",
    "combined_weighted_searcher = searchEngine('combined', combined_weight = 0.40)\n",
    "ae_bottleneck_searcher = searchEngine('ae_bottleneck_2048')\n",
    "ae_dense_searcher = searchEngine('ae_dense_2048')\n",
    "ae_simple_searcher = searchEngine('ae_simple_2048')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined encoders loaded.\n",
      "Combined encoders loaded.\n"
     ]
    }
   ],
   "source": [
    "resnet_1000_searcher.load_encoder()\n",
    "resnet_2048_searcher.load_encoder()\n",
    "combined_searcher.load_encoder()\n",
    "combined_weighted_searcher.load_encoder()\n",
    "ae_bottleneck_searcher.load_encoder()\n",
    "ae_dense_searcher.load_encoder()\n",
    "ae_simple_searcher.load_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_paths = [\n",
    "               \n",
    "              ]\n",
    "\n",
    "for query_img_path in query_paths:\n",
    "    resnet_1000_searcher.encoder_search(query_img_path, 5)\n",
    "    resnet_2048_searcher.encoder_search(query_img_path, 5)\n",
    "    combined_searcher.encoder_search(query_img_path, 5)\n",
    "    combined_weighted_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_bottleneck_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_dense_searcher.encoder_search(query_img_path, 5)\n",
    "    ae_simple_searcher.encoder_search(query_img_path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 \"/Users/ChrisPenny/Downloads/fxslide3.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/fxslide3 copy.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Desktop/IMG_3657.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/F-35A_flight_(cropped).jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/1583454329186.jpeg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/1-corvette-stingray-c8-2019-fd-hr-hero-front_0.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/5e48cf3d-0992-4eda-a080-e00e07738b2f.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/Van-Gogh-starry-night-print2.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/cb4b3ea65d0b315e153116ecd9043070.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/366ad6eb4f5923b3148f2ae7616f1225.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/Dogs+and+Puppies+%27Mona+Lisa+Pet%27+Graphic+Art+Print+on+Wrapped+Canvas.jpg\",\n",
    "#                 \"/Users/ChrisPenny/Downloads/images (1).jpeg\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
