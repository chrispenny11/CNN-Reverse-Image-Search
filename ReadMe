Chris Penny
MPCS 53112
Final Project
December 3, 2020

REPOSITORY: https://github.com/chrispenny11/CNN-Reverse-Image-Search

NOTE: Model weights must be downloaded from Google Drive and placed in a 'models' directory!
Link: https://drive.google.com/drive/folders/1hXkbdtZ65Tao4PSG36FrYKApoO5vQ1Hv?usp=sharing

## SEARCHENGINE CLASS ##

Most of the encoding, processing, and collection of search results was performed using a 'searchEngine' class designed to take a user input denoting the desired encoding type.  This allowed one set of written methods to perform necessary steps across the eight encoding types (listed below):

1. ResNet50, 1,000:  ResNet50 architecture’s final prediction layer.  
2. ResNet50, 2,048:  Resnet50 architecture’s penultimate layer.  Output of a GlobalAveragePooling2D layer on a (batch size, 7, 7, 2048).
3. AE Simple, 2,048:  ‘Simple’ autoencoder model’s (batch size, 7, 7, 224) tensor passed through a GlobalMaxPooling2D layer.   
4. AE Dense, 2,048:  ‘Dense’ autoencoder model’s (batch size, 7, 7, 224) tensor passed through a GlobalMaxPooling2D layer.   
5. AE Bottleneck, 2,048:  ‘Bottleneck’ autoencoder model’s minimum dimension, of size (batch size, 2,048).
6. Combined, 3,048:  A direct concatenation of the ResNet50, 1,000 encoding and the AE Bottleneck, 2,048 encoding. Constituent encodings are normalized prior to concatenation. 
7. Weighted Combined, 3,048:  A concatenation of the ResNet50, 1,000 encoding and the AE Bottleneck, 2,048 encoding.  Constituent encodings are normalized prior to concatenation with a scalar of 0.4 applied to the ResNet50 encodings.
8. ResNet50 Normalized, 1,000:  ResNet50 architecture’s final prediction layer but a normalizing step is applied.

The searchEngine class can be found as code setup to run on the limited number of sample encodings within this repository.  In the pushed copy of the repository, the Search Engine.ipynb notebook demonstrates the process of encoding generation.  An additional notebook - html_notebooks/12.3.2020 Final Search Engine with Examples - is included as an html file that demonstrates how to use the searching and scoring features of the class type as well as a large number of additional examples not shown in the written report.  If you scroll through the images too quickly you may miss code.  Note that this additonal notebook was run using explicit filepaths that are not featured in the uploaded code due to a desire to avoid damaging the core version of the code.

Each method of the class has a document string detailing its purpose and inputs.  Unless necessary, comments have been removed for code readability.  Please feel free reach out if there are any questions!

## AUTOENCODER TRAINING ##

The notebooks used in training the three autoencoder models are included as html files.  Each html file contains a saved copy of the notebook saved after training, including the creation of the model architecture.  Essentially, these notebooks represent the finalized Autoencoder models.  Note that some cells are incomplete due to connection failure, as described in the report.  Regardless, the attached html files show the Keras code used to train the models, which were then saved as h5 files.  Additionally, numerous examples of reconstructed images can be found in each of the three notebooks:

1. Simple: html_notebooks/11.19.2020 AE_Simple_F4_0001.html
2. Dense: html_notebooks/11.20.2020 AE_Dense_F4_0001.html
3. Bottleneck: html_notebooks/11.21.2020 AE_Bottleneck_F4_0001.html


## PLOTS AND ANALYSIS ##

All recorded scoring information was saved and has been uploaded in the plots_and_analysis directory.  In addition, this directory features a Jupyter Notebook that was used to produce the plots featured in the report.  This directory contains:

 - A jupyter notebook with all of the analysis plotting: Plots and Analysis.ipynb
 - The generated raw data for scores for every tested sensitivity.  Note that if data is hardcoded in the notebook, then it either came from the html files ( training performance) or from a printout after code ran (runtime analysis).

## SUBMITTED DIRECTORY STRUCTURE DESCRIPTION ##

ImageNet:  Contains csv's with class schemes and a sample of 500 images drawn from 10 classes in a folder titled 'organized_validation_resnet.'  Images are taken from the validation partition, which was used as a test set.

development_notebooks:  Contains documentation of development in the form of working Jupyter Notebooks.  The notebooks are dated by creation date, although some early notebooks went unsaved :(

encodings:  Contains generated encodings.  In the submitted repository, these encodings have been pregenerated on the limited dataset (as seen in Search Engine.ipynb).

html_notebooks:  This is a directory with four very important notebooks saved in html format.  They are called about in the information at the top of the readme and contain information about autoencoder training and a number of examples derived from the full validation dataset.

plots_and_analysis:  Contains the raw data generated by the scoring procudures and a notebook used to generate report figures as described in ## PLOTS AND ANALYSIS ##.

Search Engine.ipynb:  Notebook containing the workhorse searchEngine class described in ## SEARCHENGINE CLASS ##.

distributed_prototype.py:  Contains the MRJob script to perform the distributed Euclidean search.

test_query_image.jpg:  A test image to demo searchEngine features.




